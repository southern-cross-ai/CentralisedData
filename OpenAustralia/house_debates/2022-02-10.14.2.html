<!--https://www.openaustralia.org.au/debates/?id=2022-02-10.14.2-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <title>
   Social Media (Anti-Trolling) Bill...: 10 Feb 2022: House debates (OpenAustralia.org)
  </title>
  <meta content="Making parliament easy." name="description"/>
  <meta content="Parliament, government, House of Representatives, Senate, Senator, MP, Member of Parliament, MPs, Australia, Australian, Social Media (Anti-Trolling) Bill...: 10 Feb 2022" name="keywords"/>
  <meta content="5FBaCDi8kCKdo4s64NEdB5EOJDNc310SwcLLYHmEbgg=" name="verify-v1"/>
  <meta content="width=device-width; initial-scale=1.0; maximum-scale=1.0" name="viewport">
   <link href="mailto:contact@openaustralia.org" rel="author" title="Send feedback"/>
   <link href="http://www.openaustralia.org.au/" rel="home" title="Home"/>
   <link href="/" rel="start" title="Home"/>
   <!-- skin: mobile -->
   <link href="/style/default/global_non_ns4_mobile.css" rel="stylesheet" type="text/css"/>
   <link href="/style/default/mobile.css" rel="stylesheet" type="text/css"/>
   <link href="/style/default/print.css" media="print" rel="stylesheet" type="text/css"/>
   <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
   </script>
   <script type="text/javascript">
    var pageTracker = _gat._getTracker("UA-3107958-3");
pageTracker._initData();
pageTracker._trackPageview();
   </script>
  </meta>
 </head>
 <body>
  <div id="container">
   <a name="top">
   </a>
   <div id="banner">
    <div id="title">
     <h1>
      <a href="/" title="To the front page of the site">
       <img alt="OpenAustralia.org beta" height="32" src="/images/openaustraliaorgbeta.gif" width="262"/>
      </a>
     </h1>
    </div>
   </div>
   <!-- end #banner -->
   <div id="content">
    <div class="stripe-head-1">
     <div class="main">
      <h2>
       House debates
      </h2>
      <h3>
       Thursday, 10 February 2022
      </h3>
      <h4>
       Bills
      </h4>
      <h5>
       Social Media (Anti-Trolling) Bill 2022; Second Reading
      </h5>
      <p>
       10:37 am
      </p>
      <a name="g14.3">
      </a>
      <p class="speaker">
       <a href="/mp/?m=587" title="See more information about Paul Fletcher">
        <img alt="Photo of Paul Fletcher" class="portrait" src="/images/mps/10723.jpg"/>
        <strong>
         Paul Fletcher
        </strong>
       </a>
       <small>
        (Bradfield, Liberal Party, Minister for Communications, Urban Infrastructure, Cities and the Arts) |
        <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A10%2F2%2F2022;rec=0;resCount=Default" title="The source of this piece of text">
         Hansard source
        </a>
        <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2022-02-10.14.3&output=js-link"></script> -->
       </small>
       <p>
        I move:
       </p>
       <p class="italic">
        That this bill be now read a second time.
       </p>
       <p>
        <a href="http://en.wikipedia.org/wiki/Social_media" rel="nofollow">
         Social media
        </a>
        services have provided Australians significant social, educational and economic benefits for many years. However, these benefits have also come with greater exposure to online harms—including exposure to emotional, mental health and financial harms that can result where malicious online trolls post defamatory material to attack a person's reputation.
       </p>
       <p>
        The Australian government is committed to keeping Australians safe from online harm, including the harmful impacts of defamatory material posted anonymously on social media.
       </p>
       <p>
        Today we introduce the Social Media (Anti-Trolling) Bill, to ensure defamation law is fit-for-purpose in the digital age and to empower Australians to respond appropriately to defamatory attacks by anonymous social media trolls.
       </p>
       <p>
        Outline of the Bill
       </p>
       <p>
        The challenges of responding to defamatory material online crystallised after the High Court's decision in Fairfax Media Publications v Voller.
       </p>
       <p>
        In that case, a majority of the court determined that the appellant media companies were 'publishers' of defamatory comments that had been made by third parties on their Facebook pages.
       </p>
       <p>
        The decision highlights the challenges faced by individuals and businesses when it comes to defamation on social media.
       </p>
       <p>
        Following Voller, it is clear that Australians who maintain an ordinary social media page could be liable for defamatory material posted by someone else—even if they do not know about the material.
       </p>
       <p>
        The government considers it is not appropriate for Australians to face potential defamation liability for material posted by others.
       </p>
       <p>
        Many individuals and organisations simply do not have the resources to continuously monitor and moderate their social media pages, merely to manage their defamation liability risk. This bill urgently responds to the risks created by the Voller decision, to protect all Australians who maintain a normal social media page from inappropriate defamation liability.
       </p>
       <p>
        The government is also deeply concerned about the harmful impact of defamatory material posted on social media. It is in the nature of social media that harmful posts may go 'viral' and rapidly be disseminated to a wide audience, amplifying the harm. Furthermore, where defamatory material is posted anonymously, it can be very difficult for Australians to respond.
       </p>
       <p>
        Some will take no action.
       </p>
       <p>
        Some will report the attacks to the platform.
       </p>
       <p>
        Some will contact the eSafety Commissioner, or another regulator.
       </p>
       <p>
        But those who have suffered the most extreme attacks on reputation, or who are bearing the significant emotional, mental health and financial costs, may wish to consider all options to vindicate their reputation, including legal proceedings.
       </p>
       <p>
        This bill provides powerful tools to help Australians who have been subjected to defamatory attacks by anonymous social media trolls, and who may be considering legal proceedings to protect themselves.
       </p>
       <p>
        The government has developed a number of mechanisms to protect Australians from a wide range of online harms. This bill is another important tool to support Australians combat trolls online.
       </p>
       <p>
        Introductory provisions
       </p>
       <p>
        'Trolling' encompasses a range of harmful online behaviours that vary in severity from the merely annoying to the criminal. Too often, this behaviour can result in harms to the victim's mental and emotional health, and can damage the victim's reputation in the eyes of their peers.
       </p>
       <p>
        The title of the bill explicitly recognises that posting defamatory material on social media is a form of 'trolling'. The title sends a clear message, calling out defamatory attacks on reputation as a form of behaviour that is not acceptable online—particularly where those reputational attacks are made behind a cloak of anonymity. The bill focuses on defamatory trolling on social media, and in this way complements other measures on the Commonwealth statute book—like the Online Safety Act or the
        <a href="http://en.wikipedia.org/wiki/Criminal_Code" rel="nofollow">
         Criminal Code
        </a>
        —which address other forms of trolling and other online harms.
       </p>
       <p>
        Protecting page owners
       </p>
       <p>
        Part 2 of the bill deals with liability for defamatory material posted on a social media service.
       </p>
       <p>
        Specifically, the bill expressly addresses one of the outcomes of the Voller decision, in relation to an end user who operates or maintains a page on a social media service—called a 'page owner' in the bill.
       </p>
       <p>
        One of the implications of the Voller decision is that a page owner—such as a small business owner or community football club—may face defamation liability for defamatory material posted on that page owner's page.
       </p>
       <p>
        This can occur where the defamatory material was posted by someone else, in circumstances where the page owner might not even be aware of the post.
       </p>
       <p>
        Following the reasoning in the Vollerdecision, a page owner may be a publisher for the purposes of defamation law if they 'facilitate' or 'encourage' the relevant communication—for example, by allowing comments—and are therefore said to 'participate' in the communication of the defamatory matter.
       </p>
       <p>
        The government does not agree that café owners or car mechanics, or people in many other classes of work, should have to risk defamation liability to engage with their client base through social media. It is not reasonable to expect millions of Australian small-business owners to spend precious time and resources actively moderating their social media pages for potentially defamatory material.
       </p>
       <p>
        The government is also concerned that the liability risks made clear by Vollermay have a chilling effect on free speech—as page owners may censor comments or disable functionalities due to a fear of being held liable for content that they did not post. In some cases, the Voller decision may have contributed to decisions to limit the ability for the general public to interact with news and current events. We saw this, for example, when the
        <a href="http://en.wikipedia.org/wiki/US" rel="nofollow">
         US
        </a>
        news network
        <a href="http://en.wikipedia.org/wiki/CNN" rel="nofollow">
         CNN
        </a>
        blocked access to its Facebook pages in Australia after the Voller decision was handed down.
       </p>
       <p>
        Section 14 of the bill addresses these aspects of the Voller decision. It makes clear that page owners are not 'publishers' of defamatory material posted on their pages by third parties. In practice, this means a person who maintains or administers a page on a social media service will be protected from defamation liability.
       </p>
       <p>
        These protections would apply for all Australian page owners, regardless of where in the world the material may have been posted.
       </p>
       <p>
        Clarifying the liability of social media service providers
       </p>
       <p>
        Part 2 of the bill also clarifies the status of social media service providers as 'publishers' of defamatory material.
       </p>
       <p>
        Section 15 of the bill deems that social media service providers are the publishers of defamatory material posted on their platforms. The deeming provision applies to all material posted in Australia on the provider's platform.
       </p>
       <p>
        This means social media providers are accountable for defamatory material posted on their service. It reflects the significant role that providers play in promoting and disseminating content, and community expectations around the responsibilities that come with providing a service that comes with the potential for significant harm.
       </p>
       <p>
        While under current jurisprudence many social media service providers would already be publishers regardless—and in this sense the bill simply confirms the current state of the law—the provision clarifies expectations and removes the burden of proving in court that the provider was a 'publisher' of the material, particularly as that burden would otherwise fall on the victim.
       </p>
       <p>
        Stronger mechanisms to assist victims
       </p>
       <p>
        Part 2 of the bill also recognises that Australians can suffer harm because of defamatory material that is posted on social media. Social media platforms can provide an avenue for users to post information that is false and to do so in language that can be abusive and damaging.
       </p>
       <p>
        Where defamatory posts are made anonymously, it can be difficult for victims to seek legal recourse against the originator.
       </p>
       <p>
        The government acknowledges that there are many legitimate reasons that Australians may wish to be anonymous online, and the bill respects that principle and recognises that anonymity has a legitimate place in the digital ecosystem.
       </p>
       <p>
        But this does not mean that social media users should be able to abuse anonymity to defame or harm others.
       </p>
       <p>
        Accordingly, part 2 of the bill introduces pioneering reforms to 'unmask' anonymous trolls who post defamatory material on social media.
       </p>
       <p>
        There are two mechanisms in the bill which will allow a victim to obtain the poster's relevant contact details, to assist in potential defamation proceedings. A victim may choose to pursue either or both, in any order.
       </p>
       <p>
        Complaints scheme
       </p>
       <p>
        The first mechanism to unmask anonymous online trolls is the complaints scheme described in section 17 of the bill.
       </p>
       <p>
        The complaints scheme provides a quick and low-cost way for victims to raise concerns about defamatory material and obtain the poster's contact details. To meet the requirements of the bill, a social media service provider must establish a complaints scheme that satisfies the criteria in section 17 of the bill.
       </p>
       <p>
        Relevantly, to meet those requirements, the complaints process must allow a victim to make a complaint about defamatory material posted on the social media service. Within 72 hours, the social media service provider must disclose the 'country location data' of the poster. This involves a statement to the effect that, according to the geolocation technology deployed by the provider, at the time the post was made, the poster either appeared to have been located in Australia or appeared not to have been located in Australia.
       </p>
       <p>
        If the material was posted in Australia, the provider must, within 72 hours of the complaint being made:
       </p>
       <ul>
       </ul>
       <ul>
       </ul>
       <p>
        The provider must also report back to the complainant about any response or outcome from notifying the poster. This may involve the poster agreeing to remove the material, asserting that the material is not defamatory, or refusing to engage with the complainant.
       </p>
       <p>
        If the complainant is dissatisfied with the handling or outcome of the complaint, the complainant can request the poster's relevant contact details. With the poster's consent, the provider can disclose those details to the complainant.
       </p>
       <p>
        'Relevant contact details', for the purposes of the bill, are a person's name or the name by which they are known, email address, telephone number and such other information as is specified in legislative rules.
       </p>
       <p>
        Where these details are disclosed with consent, the complainant may be in a position to effect service of legal proceedings, or to seek an order for substituted service, if they wish to do so. The complaint scheme's consent requirement is an important limitation to protect the privacy of the poster and manage potential safety risks.
       </p>
       <p>
        The complaints mechanism serves a number of important purposes, even where the poster does not give consent.
       </p>
       <p>
        First, by providing country location data, it provides useful information to the complainant about whether it may be worthwhile to commence a defamation action. Victims may decide that, on balance, the difficulties involved in litigating against a foreign defendant, and potential international enforcement issues, mean that the cost and risk outweigh the benefit.
       </p>
       <p>
        Second, for material posted in Australia, the complaints mechanism will notify the poster that the complainant considers it to be defamatory, which may be enough to prompt the poster to remove the material. It may also allow the complainant to understand the poster's view on the complaint—early in the process and without needing to commence legal proceedings. This can inform the complainant's decision about their next steps.
       </p>
       <p>
        Third, for material posted in Australia, the mechanism will bring the material to the attention of the social media service provider, flagging that the complainant considers it to be defamatory. Bringing inappropriate behaviour to a provider's notice can play an important role in enforcing community standards.
       </p>
       <p>
        The complaints scheme expressly contemplates that material may be removed by consent—without either incentivising take-down or encouraging continued publication. Neither the complaints scheme nor any other part of the bill affects existing mechanisms that exist to allow take-down of defamatory and harmful content.
       </p>
       <p>
        End-user information disclosure orders
       </p>
       <p>
        The second mechanism in the bill by which a victim may 'unmask' an anonymous social media troll is a new form of court order set out in Part 3 of the bill—called an 'end-user information disclosure order'.
       </p>
       <p>
        These disclosure orders can be granted against a social media service provider by an Australian court with jurisdiction to hear a defamation dispute, or Division 2 of the
        <a href="http://en.wikipedia.org/wiki/Federal_Circuit" rel="nofollow">
         Federal Circuit
        </a>
        and Family Court of Australia.
       </p>
       <p>
        An Australian person may apply for a disclosure order where:
       </p>
       <ul>
       </ul>
       <ul>
       </ul>
       <ul>
       </ul>
       <ul>
       </ul>
       <ul>
       </ul>
       <ul>
       </ul>
       <ul>
       </ul>
       <p>
        Where the court is appropriately satisfied, they may grant a disclosure order. Relevantly, this includes being satisfied that there are reasonable grounds to believe that there may be a right for the prospective applicant to obtain relief against the poster in a defamation proceeding that relates to the material.
       </p>
       <p>
        Should the court grant the order, the social media service provider will be required to provide the victim with the poster's country location data and, if the material was posted in Australia, the poster's relevant contact details.
       </p>
       <p>
        Empowering the courts to issue these orders, based on an assessment of whether there is a right to obtain relief in defamation, will provide an expedient and enforceable approach to unmasking anonymous trolls, while protecting the privacy of users where the claim is baseless.
       </p>
       <p>
        The bill also ensures that the court retains the discretion to refuse to make an order, and explicitly makes clear that the court may do so where it is satisfied the disclosure of the relevant contact details or country location data is likely to present a risk to the poster's safety.
       </p>
       <p>
        These mechanisms ensure that the disclosure order regime will allow a victim to obtain the poster's relevant contact details in appropriate circumstances, with strong safeguards against abuse.
       </p>
       <p>
        Conditional defence
       </p>
       <p>
        To incentivise social media service providers to adopt and comply with the two unmasking mechanisms, the bill gives social media service providers access to a conditional defence from defamation liability. This defence is available in relation to material posted in Australia, provided the social media service provider meets certain criteria. These criteria, and the circumstances in which the defence is available, are set out in section 16 of the bill.
       </p>
       <p>
        Broadly speaking, to make out the defence the provider must have a complaints scheme that meets the prescribed requirements.
       </p>
       <p>
        If a complaint is made under that scheme, the provider must comply with the scheme in relation to the handling of the complaint.
       </p>
       <p>
        If the victim requests the poster's relevant contact details—either in response to a complaint or through a court order—the provider must disclose those details to access the defence.
       </p>
       <p>
        If a social media service provider is unable or unwilling to disclose the contact details to the victim, they will not be able to access the defence—and will therefore face potential defamation liability. This ensures that, even if victims are not able to obtain the poster's contact details, they are not left without an appropriate defendant against whom they can commence defamation action.
       </p>
       <p>
        Nominated entity requirements
       </p>
       <p>
        Part 4 of the bill sets out requirements in relation to nominated entities.
       </p>
       <p>
        The bill recognises that many providers of social media services are entities incorporated in a foreign country. Pursuing legal action against those entities can cause difficulties in relation to access and enforcement of civil judgments. Even seeking to make a complaint to a company located in another country can raise challenges.
       </p>
       <p>
        To address these challenges, the bill requires foreign providers of social media services that meet specified thresholds to establish an Australian 'nominated entity'.
       </p>
       <p>
        This obligation will apply to a social media service provider that is a body corporate incorporated in a foreign country, where:
       </p>
       <ul>
       </ul>
       <ul>
       </ul>
       <p>
        The nominated entity must be the provider's agent, must be incorporated in Australia, and must have an office in Australia.
       </p>
       <p>
        Among other things, the nominated entity must also have access to country location data and relevant contact details of users, in respect of material posted in Australia, and be authorised to receive complaints and requests for contact details under the complaints scheme.
       </p>
       <p>
        The net effect of these provisions is that, where complainants seek to make complaints or serve a disclosure order, there will be an Australian entity, with an Australian office, capable of receiving the complaint or being served with a court order. That entity will be in a position to comply with those mechanisms to provide contact details where required to do so by the bill.
       </p>
       <p>
        This will make it significantly easier for Australians to obtain information about a poster (where permitted by the bill) and then to commence proceedings if that is what they decide to do.
       </p>
       <p>
        The obligation is a civil penalty provision, enforceable by a fine of up to 500 penalty units. Furthermore, a provider that is subject to the obligation must have established a nominated entity by the time material was posted on its service if it wishes to access the conditional defence in defamation proceedings about that material.
       </p>
       <p>
        These mechanisms will incentivise a social media service provider to establish an appropriate nominated entity to act as its Australian agent.
       </p>
       <p>
        Attorney-General intervention and legal assistance
       </p>
       <p>
        Part 5 of the bill sets out miscellaneous provisions, including powers with respect to intervention in defamation proceedings.
       </p>
       <p>
        Specifically, section 25 of the bill sets out two alternative bases on which the Attorney-General may intervene in a proceeding.
       </p>
       <p>
        Subsection 25(1) provides that the Attorney-General may intervene in a proceeding on behalf of the Commonwealth where, amongst other things, the provider of the social media service is a party to the defamation proceeding, and the Attorney-General believes it is in the public interest to do so.
       </p>
       <p>
        The provision makes clear the Attorney-General may intervene in defamation proceedings where the provider of the social media is a party—even if the proceeding does not arise under this bill—provided the matter is in federal jurisdiction.
       </p>
       <p>
        Defamation cases can be complex and can sometimes involve a significant power imbalance between a large provider and an individual whose reputation has been harmed. In part, the power to intervene under subsection 25(1) would allow the Attorney-General to address this imbalance, where it is in the public interest to do so.
       </p>
       <p>
        Subsection 25(2) provides an alternative and additional basis of intervention. The provision makes clear that the Attorney-General may intervene in a matter arising under the bill. This includes proceedings that are not defamation proceedings, such as applications for a disclosure order (where substantive defamation proceedings have not commenced).
       </p>
       <p>
        This power of intervention will allow the government to put its views to the court about how this novel piece of legislation is intended to apply.
       </p>
       <p>
        The bill also recognises that intervention may be associated with increased legal costs. Accordingly, where the Attorney-General has intervened in proceedings instituted by an Australian person, section 25 of the bill allows the Attorney-General to authorise the payment of legal costs to that person. Such a payment may be authorised where, in the opinion of the Attorney-General, the proceeding will:
       </p>
       <ul>
       </ul>
       <ul>
       </ul>
       <p>
        This ensures that, in appropriate circumstances, Australians are not financially disadvantaged in proceedings in which the Attorney-General has intervened.
       </p>
       <p>
        Conclusion
       </p>
       <p>
        The Australian government is committed to supporting the safety of Australians online and is unwavering in its commitment to respond to the challenges and opportunities presented by new technologies.
       </p>
       <p>
        This bill is a strong addition to the government's world-leading measures to address online harms and provide appropriate safeguards to all Australians. I commend the bill to the House.
       </p>
       <p>
        Debate adjourned.
       </p>
       <br/>
       <br/>
       <br/>
       <br/>
       <div id="footer">
        <p>
         <a href="/?show_pc">
          View the PC OA website
         </a>
        </p>
       </div>
      </p>
     </div>
    </div>
   </div>
  </div>
 </body>
</html>
