<!--https://www.openaustralia.org.au/debates/?id=2023-09-11.223.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <title>
   Freedom of Speech: 11 Sep 2023: House debates (OpenAustralia.org)
  </title>
  <meta content="Making parliament easy." name="description"/>
  <meta content="Parliament, government, House of Representatives, Senate, Senator, MP, Member of Parliament, MPs, Australia, Australian, Freedom of Speech: 11 Sep 2023" name="keywords"/>
  <meta content="5FBaCDi8kCKdo4s64NEdB5EOJDNc310SwcLLYHmEbgg=" name="verify-v1"/>
  <meta content="width=device-width; initial-scale=1.0; maximum-scale=1.0" name="viewport">
   <link href="mailto:contact@openaustralia.org" rel="author" title="Send feedback"/>
   <link href="http://www.openaustralia.org.au/" rel="home" title="Home"/>
   <link href="/" rel="start" title="Home"/>
   <!-- skin: mobile -->
   <link href="/style/default/global_non_ns4_mobile.css" rel="stylesheet" type="text/css"/>
   <link href="/style/default/mobile.css" rel="stylesheet" type="text/css"/>
   <link href="/style/default/print.css" media="print" rel="stylesheet" type="text/css"/>
   <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
   </script>
   <script type="text/javascript">
    var pageTracker = _gat._getTracker("UA-3107958-3");
pageTracker._initData();
pageTracker._trackPageview();
   </script>
  </meta>
 </head>
 <body>
  <div id="container">
   <a name="top">
   </a>
   <div id="banner">
    <div id="title">
     <h1>
      <a href="/" title="To the front page of the site">
       <img alt="OpenAustralia.org beta" height="32" src="/images/openaustraliaorgbeta.gif" width="262"/>
      </a>
     </h1>
    </div>
   </div>
   <!-- end #banner -->
   <div id="content">
    <div class="stripe-head-1">
     <div class="main">
      <h2>
       House debates
      </h2>
      <h3>
       Monday, 11 September 2023
      </h3>
      <h4>
       Private Members' Business
      </h4>
      <h5>
       Freedom of Speech
      </h5>
      <p>
       5:38 pm
      </p>
      <a name="g223.2">
      </a>
      <p class="speaker">
       <a href="/mp/?m=766" title="See more information about Russell Broadbent">
        <img alt="Photo of Russell Broadbent" class="portrait" src="/images/mps/10069.jpg"/>
        <strong>
         Russell Broadbent
        </strong>
       </a>
       <small>
        (Monash, Liberal Party) |
        <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
         Hansard source
        </a>
        <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.223.2&output=js-link"></script> -->
       </small>
       <p>
        Thank you for the opportunity to continue my opposition to this crazy bill that's going to be put before the parliament eventually. For 45 years Professor Ian Brighthope has practised medicine, especially in the area of chest complaints and viral infections. I am making the point because what will happen with this legislation only reinforces what is already happening—discrimination against people making remarks that are not suitable to the general public, not suitable to the government of the day, not suitable to the bureaucrats of the day. It says here:
       </p>
       <p class="italic">
        Your account was restricted due to multiple violations of LinkedIn's User Agreement and Professional Community Policies against sharing content that contains misleading or inaccurate information.
       </p>
       <p>
        What he did, his one crime, was share a post from Professor Catherine Bennett:
       </p>
       <p class="italic">
        We only needed one lockdown, one test and one treatment for all.
       </p>
       <p class="italic">
        <a href="http://en.wikipedia.org/wiki/Vitamin_D" rel="nofollow">
         Vitamin D
        </a>
        test, Vitamin D treatment.
       </p>
       <p class="italic">
        Did not appear in any of the modelling.
       </p>
       <p class="italic">
        Australia failed as did the
        <a href="http://en.wikipedia.org/wiki/WHO" rel="nofollow">
         WHO
        </a>
        and all its agencies.
       </p>
       <p class="italic">
        Remind me again why we keep locking up the entire Australian population in the fight against Covid-19. A grand total of 21 people under 60 died with or of Covid in 2020.
       </p>
       <p>
        Now she has no right to proffer an opinion across social media? I can go on and see what she said in the rest of the post, but it doesn't make any difference. The point here is: this misinformation and disinformation bill will only be a vehicle for those people who want to close down debate, and we've seen enough of closing down debate in this nation. What we need is conversation where it's free for all to discuss their opinions.
       </p>
       <p>
        I put to someone today, 'The Australian people are not stupid with regard to finances, with regard to advice they're given by anybody.' They are not. My mentor at school, in commercial practice, was Jack Kroger, who was Michael Kroger's father, who's a Liberal Party stalwart. He said to me, 'Russell, caveat emptor. Let the buyer beware.' I say let the people of Australia decide on what is misinformation and what is disinformation. Give them the authority to make up their own mind. With that, Deputy Speaker Sharkie, I thank you for the opportunity. I think there's another 40 minutes in me on this subject!
       </p>
       <p>
        5:41 pm
       </p>
       <a name="g224.1">
       </a>
       <p class="speaker">
        <a href="/mp/?m=752" title="See more information about Kate Thwaites">
         <img alt="Photo of Kate Thwaites" class="portrait" src="/images/mps/10930.jpg"/>
         <strong>
          Kate Thwaites
         </strong>
        </a>
        <small>
         (Jagajaga, Australian Labor Party) |
         <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
          Hansard source
         </a>
         <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.224.1&output=js-link"></script> -->
        </small>
        <p>
         Misinformation and disinformation are real, and they can have serious consequences for the safety and wellbeing of Australians. They can be seriously harmful. They can be designed to sow division within our communities. They can be designed to undermine our trust in each other, in our public institutions, in our organisations and even in our democracy. Misinformation and disinformation can be designed to threaten public health and safety. So it is something that I am concerned about. It is something that this government is, rightly, concerned about. And this is why we plan to tackle this threat of misinformation and disinformation with responsible measures that will make a difference.
        </p>
        <p>
         Australians do know that there is misinformation and disinformation out there being spread by algorithms, largely through social media, and we have seen that in the context of the pandemic and others over the previous years. A recent University of Canberra study found that 66 per cent of people said they encountered misinformation on social media about COVID-19. Twenty-three per cent encountered what they called a lot of misinformation, 36 per cent encountered some misinformation and 30 per cent of people were forwarded misinformation from someone they know—false and misleading information about treatments and how to prevent exposure, information that was designed to sow discord, that was designed to mislead people.
        </p>
        <p>
         We know that misinformation is also a problem in the area of national security, where malicious actors are using digital disinformation to infiltrate and influence public discourse. And this has been found in our select committee on foreign interference, which tabled its report on what risks Australia faces in this area. It highlighted that regimes continue to pose an unacceptable risk through targeted online misinformation campaigns that leverage social media platforms to skew public debate, undermine trust in our democratic institutions and establish narratives that favour the interests of authoritarian states. The report went on to note that the growth in technologies, including artificial intelligence, is making it easier and easier to conduct misinformation campaigns.
        </p>
        <p>
         <a href="http://en.wikipedia.org/wiki/Social_media" rel="nofollow">
          Social media
         </a>
         platforms themselves have recognised that there is a threat from misinformation and disinformation. In Australia, platforms have signed up to a voluntary Australian code of practice on disinformation and misinformation. The code commits its signatories to implement safeguards that limit the spread of misinformation and disinformation on their platforms and to report annually on their commitment to this work. This is a good start, and it has been recognised as such. Industry bodies have also said that they want more from government; they do want government to regulate in this important area.
        </p>
        <p>
         Essentially, we have a choice. We can have legislation from government; we can have involvement from a democratically elected government in the space, or we can leave this space entirely to tech billionaires and foreign malicious actors. That is essentially what we're talking about here. Our government has identified that we need to do more. The spread and influence of misinformation and disinformation by people is something that we need to act on now. Australians do need to be protected from the seriously harmful content that can be spread online, and we can do this as a federal government.
        </p>
        <p>
         The exposure draft of this bill builds on the voluntary code already in place by boosting
         <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
          ACMA
         </a>
         's ability to hold digital platforms to account. ACMA will have new information gathering powers to improve transparency around what platforms are doing to combat misinformation and disinformation—content that is false, misleading or deceptive that causes or can contribute to serious harm to Australians.
        </p>
        <p>
         ACMA would be able to register enforceable industry codes with penalties for noncompliance. ACMA would have the power to require their industry to lift the bar where systemic issues amongst platforms are identified, and the standards used could include measures like stronger tools to support users to report misinformation and disinformation, more robust complaints handling and enabling the more extensive use of fact checkers.
        </p>
        <p>
         It is important to note that the legislation does not give ACMA the power to remove or deal with individual pieces of information. This is about transparency and systems.
        </p>
        <p>
         We saw that the former government previously committed to empowering ACMA to take action on misinformation and disinformation, yet, now they are opposing it. They have decided, it seems, that because they are in opposition they no longer need to take these very serious threats seriously.
         <a href="http://en.wikipedia.org/wiki/The_Liberals" rel="nofollow">
          The Liberals
         </a>
         and Nationals now appear to be unfazed by the need to protect Australians from harmful information.
        </p>
        <p>
         Industry knows we need to take action. The Australian community is looking to us for action. It is incredibly important for our democracy, for our institutions and for the conversations we have as a country that we do address the threat presented by misinformation and disinformation, and that is what the government is attempting to do.
        </p>
        <p>
         5:46 pm
        </p>
        <a name="g225.1">
        </a>
        <p class="speaker">
         <a href="/mp/?m=763" title="See more information about Zali Steggall">
          <img alt="Photo of Zali Steggall" class="portrait" src="/images/mps/10941.jpg"/>
          <strong>
           Zali Steggall
          </strong>
         </a>
         <small>
          (Warringah, Independent) |
          <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
           Hansard source
          </a>
          <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.225.1&output=js-link"></script> -->
         </small>
         <p>
          I rise to speak on this motion moved by the member for Banks. Whilst I agree that there are significant concerns with the proposed government legislation, I want to be very clear that I do support that the government needs to address misinformation and disinformation. We only have to look at what is happening daily on social media platforms around the debate on the referendum to see how important it is to address misinformation and disinformation.
         </p>
         <p>
          I do find it incredible that both sides of this House can't come together on this issue. When we stop and look at the events of the
          <a href="http://en.wikipedia.org/wiki/US" rel="nofollow">
           US
          </a>
          6 January uprises, they were very much fuelled by misinformation and disinformation. It should really be a testament to all of us as to how precious democracy can be but also how quickly you can erode trust in outcomes. That's why it is so important to address misinformation and disinformation.
         </p>
         <p>
          In this bill, the member for Banks is calling on the government to admit that its plan is deeply flawed and to bin the bill, but that is just wiping your hands of any responsibility to fix this problem. So, yet again, I have an issue with the opposition in this respect. Some of the criticisms raised are the exemption of governments, academics and others from the application of the powers concerning misinformation and the inappropriate breath of the definition of misinformation itself.
         </p>
         <p>
          Whilst I agree, in general, with some of these criticisms, there are many others that we need to really consider. I have to object to the idea that the response is just to bin the bill. A productive, useful opposition comes to the table to actually work out better legislation that will keep all of our community safe from misinformation and disinformation. We need to acknowledge the problem of misinformation and disinformation and seek to grapple with the issue it purports to address, so it's just not enough to say bin it and leave it at that.
         </p>
         <p>
          The public is greatly concerned with misinformation and disinformation, especially on online platforms where we know the vast majority of news and information is consumed, especially by younger generations. According to a
          <a href="http://en.wikipedia.org/wiki/Roy_Morgan" rel="nofollow">
           Roy Morgan
          </a>
          survey, over two-thirds of Australian adults felt they had been exposed to deceptive news items. Another study found that a quarter of a sample felt they had read stories that were completely made up. More recently, the Australia Institute's exit poll of the 2022 election found that 73 per cent of Australians came across misleading political advertising during the election campaign, and this last finding is particularly disturbing as it strikes at the very heart of our democratic system.
         </p>
         <p>
          <a href="http://en.wikipedia.org/wiki/Social_media" rel="nofollow">
           Social media
          </a>
          companies and the power they have when it comes to the dissemination of news and information on digital platforms—the current major players of the digital platform area are keenly alive to the public's dissatisfaction with the ineffective regulation of online content. They are openly involved in developing codes for self-regulation, notably the Australian Code of Practice on Disinformation and Misinformation 2021, commonly known as the
          <a href="http://en.wikipedia.org/wiki/DIGI" rel="nofollow">
           DIGI
          </a>
          code. Ironically it was the coalition government who were the keen supporters and developers of that code and often hid behind this voluntary code when asked to do more to regulate this sector. But the issue is clearly of major concern to the digital platform providers. The success of this code is yet to be evaluated, as it was only introduced 2021, but the issue is obviously not going to go away, and the public is open to attempts to curb the more sinister and pernicious effects of rampant disinformation and misinformation online.
         </p>
         <p>
          I have two major concerns with the current approach, which I address to both major parties. Ultimately, neither side has been in a hurry to address misleading and deceptive political advertising, in particular in relation to the referendum. I've proposed solutions in a private member's bill. This reform is long overdue and is supported by voters of both persuasions. We know that it's a concrete and manageable target that can be achieved by existing and well-tried concepts that are familiar to the courts in relation to misleading and deceptive conduct, without introducing difficult and challengeable concepts, such as 'misinformation' and 'disinformation'. So we do need to look at these issues, but I am concerned by the proposal of the government that wideranging powers of this kind over digital platform providers should be entrusted to the
          <a href="http://en.wikipedia.org/wiki/Australian_Communications_and_Media_Authority" rel="nofollow">
           Australian Communications and Media Authority
          </a>
          .
          <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
           ACMA
          </a>
          's performance in regulating existing broadcast media is questionable, and I call on the government to publish a full and independent assessment of ACMA's current performance.
         </p>
         <p>
          5:51 pm
         </p>
         <a name="g226.1">
         </a>
         <p class="speaker">
          <a href="/mp/?m=793" title="See more information about Tania Lawrence">
           <img alt="Photo of Tania Lawrence" class="portrait" src="/images/mps/10981.jpg"/>
           <strong>
            Tania Lawrence
           </strong>
          </a>
          <small>
           (Hasluck, Australian Labor Party) |
           <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
            Hansard source
           </a>
           <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.226.1&output=js-link"></script> -->
          </small>
          <p>
           I rise to speak against the motion. This proposed legislation seeks to allow the
           <a href="http://en.wikipedia.org/wiki/Australian_Communications_and_Media_Authority" rel="nofollow">
            Australian Communications and Media Authority
           </a>
           to require records from digital platforms, to register industry generated codes for the monitoring and removal of misinformation and disinformation, and to impose a code where that does not happen or where the industry code is inadequate. There are safeguards built in, with certain content excluded by definition from the operation of the provisions, such as entertainment, parody and satire, professional news, government sources and education. Further, there is an express protection in clause 60 which refers to the implied freedom of political communication. Private messages are exempt.
          </p>
          <p>
           The exclusions and protections show that the targets of the legislation are malevolent actors, both domestic and international, who seek intentionally to do harm as well as those who unintentionally would enable harm to be done through publicly available online platforms. The definition covers content which is 'false, misleading or deceptive', which is likely to cause or contribute to 'serious harm' and which is provided on a digital service and spread at scale. This doing of harm through misinformation and disinformation is already an issue in the online world. It is set to become a much bigger issue as the use of powerful
           <a href="http://en.wikipedia.org/wiki/AI" rel="nofollow">
            AI
           </a>
           will mean exponential growth. That is why the communications regulator needs to have the tools to take action, and that is why legislation is required. The coalition knows this and that's why, on their website, even today, under the headline, 'Protecting Australians online', we find the following statement:
          </p>
          <p class="italic">
           A re-elected coalition government will continue to protect you and your family online by:
          </p>
          <p>
           …    …   …
          </p>
          <ul>
          </ul>
          <p>
           That is exactly what we are doing in this exposure draft. You need to read your statements, Keith, before you stand up!
          </p>
          <p>
           Why is there the apparent confusion amongst the coalition? Why do they say one thing on their website and another thing in this motion? We have to doubt the coalition's preparedness to actually protect people online, when they spend nine years not arming the regulator, then go to an election promising to arm the regulator and then pretend to totally oppose the legislation to arm the regulator, once it is out for consultation. The other explanation might be some sort of schism in the Liberal Party. The member for Banks is the shadow minister for communications. He now calls for the draft bill to be binned. It begs the question: Is the shadow minister suggesting that the Australian government do nothing to combat misinformation and disinformation? Is he suggesting that we should leave the Australian regulator powerless in the face of this modern-day threat? Is he suggesting the Australian government should do nothing to combat foreign interference by disinformation? Is the opposition suggesting that we should just leave digital platforms to make up their own rules, without any oversight?
          </p>
          <p>
           In the recent past, the former coalition Minister for Communications, the member for Bradfield, stated:
          </p>
          <p class="italic">
           … It is in the nature of social media that harmful posts may go 'viral' and rapidly be disseminated to a wide audience, amplifying the harm…
          </p>
          <p>
           He referred to:
          </p>
          <p class="italic">
           … the significant role that providers play in promoting and disseminating content, and community expectations around the responsibilities that come with providing a service that comes with the potential for significant harm.
          </p>
          <p>
           This amount of recorded support in the
           <i>
            Hansard
           </i>
           and in Liberal Party documentation for this very sort of legislation leaves a question mark over the sudden, vehement opposition by the member for Banks. Nevertheless, this is an exposure draft, and the purpose is to receive submissions from interested organisations and improve the draft before it goes to the parliament.
          </p>
          <p>
           I have seen a number of useful submissions, and, when constituents approach my office with concerns, I have been urging them to also make submissions. I note that the Interactive Games and Entertainment Association wants to ensure that the bill doesn't inadvertently gather up legitimate online gaming interests, and that the Human Rights Law Centre thinks it doesn't go far enough. The
           <a href="http://en.wikipedia.org/wiki/Victorian_Bar" rel="nofollow">
            Victorian Bar
           </a>
           association position is so similar to that of the member for Banks that I wonder which came first.
          </p>
          <p>
           In the end, it is a matter of finding a good balance and ensuring that free political discourse is not impinged upon. This isn't really a matter of the coalition being against this draft bill, which they committed to bringing into effect themselves, prior to the election. It's just another example of a coalition so policy paralysed that, instead of being a constructive party of the parliamentary process, they feel the need to scramble around seeing which fringe groups they can incite into action to build a Liberal Party mailing list.
          </p>
          <p>
           5:56 pm
          </p>
          <a name="g227.1">
          </a>
          <p class="speaker">
           <a href="/mp/?m=609" title="See more information about Michael McCormack">
            <img alt="Photo of Michael McCormack" class="portrait" src="/images/mps/10743.jpg"/>
            <strong>
             Michael McCormack
            </strong>
           </a>
           <small>
            (Riverina, National Party, Shadow Minister for International Development and the Pacific) |
            <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
             Hansard source
            </a>
            <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.227.1&output=js-link"></script> -->
           </small>
           <p>
            There's one thing I'll say about the member for Banks:
            <a href="http://en.wikipedia.org/wiki/David_Coleman" rel="nofollow">
             David Coleman
            </a>
            is very careful and considered, and he has put forward a very astute private member's motion here. Noting that the government is seeking to impose new misinformation laws, he quite accurately describes them as 'deeply flawed', because they are.
           </p>
           <p>
            Even before submissions closed on 20 August, the government's exposure draft bill had been subjected to widespread criticism. Some of those who came out vehemently against it were leading lawyers. They have looked at the government's bill and absolutely taken it apart, piece by piece. The minister, as much as I like the member for Greenway, has had few defenders of her plan.
           </p>
           <p>
            I've received a number of pieces of correspondence about this. Many of them have come from Parkes, in the northern part of my electorate. Liz Naveau says: 'Sorting fact from fiction is not always easy. What someone thinks is true might be what someone else thinks is false.' I actually said that in a press conference in Queensland once and got absolutely hammered about it, but I was right then and Liz is right here. She says: 'We need debate and the free flow of information to consider ideas and arrive at the truth. Censoring debate stops this vital process.'
           </p>
           <p>
            From the same household, Neil Naveau says, 'I'm an Australian, born and bred.' He loves his country and that he's free. He says, 'The bill is another attempt to silence truth and turn this country into a controlled one.' He describes the misinformation bill as 'wrong-headed and dangerous'.
           </p>
           <p>
            Darren Stevenson, also from Parkes, says: 'Mis- and disinformation shows division within the community, undermines trust and can threaten public health and safety. The Albanese government is committed to keeping Australians safe online'—that is important. I know the work that the member for Forrest has done in this regard, but I digress. He says, 'That includes ensuring that the
            <a href="http://en.wikipedia.org/wiki/Australian_Communications_and_Media_Authority" rel="nofollow">
             Australian Communications and Media Authority
            </a>
            has the powers it needs to hold digital platforms to account for mis- and disinformation on their services.' He says that what this bill is proposing to do is dangerous. He says, 'There is no trust in the Albanese government with the ridiculous and hurtful policies that the Prime Minister and his government are implementing and dictating onto the Australian public.'
           </p>
           <p>
            There is widespread concern right across the nation about this bill. That is why the member for Banks has brought it forward. It does stifle academic debate. How can any one authority claim it can determine and regulate the supposed objective truth of science or morality? Meta, Twitter or X is concerned the bill goes too far, stifling free speech. If ever you want to see an example of free speech, go on Twitter—go on live feed to the sorts of things that people say on Twitter or on X. I don't usually block them unless they actually make comments about military ceremonies or people I have eulogised because they have passed away. Anything else I generally let go because I do believe in free speech. True liberty is when free-born men, having the right to advise the public, may speak free. Milton said that many, many, many years ago. It was as true then as it is true now. The best way to defeat bad ideas or bad speech is with free and fair debate, allowing better ideas to come forward.
           </p>
           <p>
            Overbearing regulation of speech encourages scepticism—it just simply does—and distrust of authority. If there's one thing that we need from this place now, it is for people to believe in this institution and believe in the people who are elected to this institution, both in the House of Representatives and through the states in the Senate, to have that discourse of information. There are many people in this place who I don't agree with, but we don't silence them. We allow free debate to flow. The truth should not fear debate. Concerns that any opposition to policy will simply be labelled misinformation is something very right and very true in this debate. I commend what the member for Banks has done in this regard.
           </p>
           <p>
            6:01 pm
           </p>
           <a name="g228.1">
           </a>
           <p class="speaker">
            <a href="/mp/?m=807" title="See more information about Sally Sitou">
             <img alt="Photo of Sally Sitou" class="portrait" src="/images/mps/10995.jpg"/>
             <strong>
              Sally Sitou
             </strong>
            </a>
            <small>
             (Reid, Australian Labor Party) |
             <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
              Hansard source
             </a>
             <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.228.1&output=js-link"></script> -->
            </small>
            <p>
             Misinformation, disinformation—the facts may be false, but the consequences are real. We live in a world now where it is getting harder and harder to discern fact from fiction, and it's having a profound impact on our lives. The COVID-19 pandemic was a challenge on two fronts. It was a once-in-a-generation challenge to our healthcare systems across the world, and some remarkable achievements were made here. With our brightest scientific minds working on it, we were able to create a vaccine for COVID-19 in record time, rolling it out at an unprecedented scale and pace. But the other challenge was societal. We relied on people trusting their governments because very extensive public health measures were required to control the spread of the virus.
            </p>
            <p>
             These measures and the vaccine rollout were severely impacted by the dramatic increase in misinformation and disinformation online. In the words of the Director-General of the
             <a href="http://en.wikipedia.org/wiki/World_Health_Organization" rel="nofollow">
              World Health Organization
             </a>
             :
            </p>
            <p class="italic">
             … we're not just fighting an epidemic; we're fighting an infodemic. Fake news spreads faster and more easily than this virus, and is just as dangerous.
            </p>
            <p>
             And the problem of misinformation in culturally diverse communities was even more acute for a number of reasons. A study by
             <a href="http://en.wikipedia.org/wiki/Monash_University" rel="nofollow">
              Monash University
             </a>
             found that effective health communication is more complicated than simply translating English messages into other languages. For example, some migrant communities may be mistrustful of authorities because they cannot trust governments in their homelands. This means they may be more susceptible to messages of disinformation around the Australian government's motivations.
            </p>
            <p>
             Where culturally diverse communities get their information from is also a reason for vulnerability. A study commissioned by the
             <a href="http://en.wikipedia.org/wiki/NSW" rel="nofollow">
              NSW
             </a>
             Council of
             <a href="http://en.wikipedia.org/wiki/Social_Service" rel="nofollow">
              Social Service
             </a>
             found that only one in 10 respondents from culturally diverse backgrounds relied on government health websites as a primary source of information during the pandemic. And what was their most cited source? Facebook. These factors lead to greater susceptibility to COVID misinformation and, ultimately, to higher rates of vaccine hesitancy in many of these communities.
            </p>
            <p>
             Misinformation can pose a serious risk to public health. It can also have a corrosive effect on our democracy. The Australian Senate Select Committee on Foreign Interference through Social Media tabled its bipartisan final report on the risk posed to Australia's democracy by foreign interference through social media. It states:
            </p>
            <p class="italic">
             Foreign interference is now Australia's principal national security threat which risks significantly undermining our values, freedoms and way of life … authoritarian regimes continue to pose an unacceptable risk to democratic societies through targeted online disinformation campaigns that leverage social media platforms to skew public debate, undermine trust in our democratic institutions, and establish narratives that favour the interests of authoritarian states.
            </p>
            <p>
             This isn't a threat in the abstract. The corrosive impact of disinformation on democracies is very present and very real. An example is the May 2023 Meta transparency report, which provides a case study of actions to combat misinformation in the context of the Australian federal election.
            </p>
            <p>
             Given the profound impact misinformation and disinformation can have, it is disappointing to see the opposition retreat into sound bites. Rather than engaging constructively with the government on an issue they cite as a top priority, they are instead playing politics. Rather than engaging in good faith with the government on an issue that a bipartisan Senate select committee says is one of Australia's most pressing security challenges, they've brought a motion full of factual inaccuracies and hyperbole. Rather than working constructively to build on industry regulation, they told the government to bin the bill when the exposure draft of the bill was out for submissions.
            </p>
            <p>
             This is not a serious opposition party, because a serious opposition party wouldn't seek to undermine the Australian government by taking away one of the tools to take on foreign interference and combat harmful misinformation.
            </p>
            <p>
             6:06 pm
            </p>
            <a name="g229.1">
            </a>
            <p class="speaker">
             <a href="/mp/?m=791" title="See more information about Zoe Daniel">
              <img alt="Photo of Zoe Daniel" class="portrait" src="/images/mps/10979.jpg"/>
              <strong>
               Zoe Daniel
              </strong>
             </a>
             <small>
              (Goldstein, Independent) |
              <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
               Hansard source
              </a>
              <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.229.1&output=js-link"></script> -->
             </small>
             <p>
              Fake news is, of course, not new. People have been manipulated by false information throughout history. But the digital world has promoted a post-truth era where facts are now a matter of opinion. As a community, we urgently need to decide whether we want to have a measure of control over the information that we consume while protecting freedom of expression and avoiding government overreach. The government's proposed laws on misinformation and disinformation are therefore well timed. Their form, however, must be carefully calibrated.
             </p>
             <p>
              It's important to distinguish between misinformation and disinformation. The former refers to false or inaccurate information—getting the facts wrong—the latter to false information which is deliberately intended to mislead. In the case of the digital world, both spread fast, often in an uncontrolled way, and cause harm. In some cases, this can be outright dangerous, as was the case during COVID, when false treatments were promoted online. During Hurricane Ian in the
              <a href="http://en.wikipedia.org/wiki/US" rel="nofollow">
               US
              </a>
              in 2022, Russian news outlet Sputnik, in what was interpreted as an attempt to undermine public trust in the authorities, promoted a narrative that the US government had abandoned storm victims.
             </p>
             <p>
              I spent several years reporting on
              <a href="http://en.wikipedia.org/wiki/Donald_Trump" rel="nofollow">
               Donald Trump
              </a>
              's presidency in the United States. My observation is that Trump's deliberate seeding of disinformation throughout 2020 that the election was going to be rigged triggered the eventual storming of the
              <a href="http://en.wikipedia.org/wiki/US_Capitol" rel="nofollow">
               US Capitol
              </a>
              by patriots in January 2021. This untold damage to US democracy continues to linger, with millions of Americans continuing to believe the election was stolen, and this may yet deliver Trump a return to the
              <a href="http://en.wikipedia.org/wiki/White_House" rel="nofollow">
               White House
              </a>
              in 2024.
             </p>
             <p>
              Social cohesion, public health and safety, and political stability are all at risk from the rapid and uncontrolled spread of mis- and disinformation. Right now, according to a survey by Reset.Tech Australia, social media platforms are not living up to their own guidelines on fake news or to the Australian Code of Practice on Disinformation and Misinformation, with claims that the Voice referendum would be invalid or illegal still available for all to see. As
              <a href="http://en.wikipedia.org/wiki/La_Trobe_University" rel="nofollow">
               La Trobe University
              </a>
              states in its 2021
              <i>
               Fighting Fake News
              </i>
              report, traditional media can also contribute to the problem through the amplification of fake news. But, as Associate Professor Andrea Carson asks: what's the best way to manage it? How can it be done without government overreach, which risks the freedom and diversity of expression necessary in healthy democracies?
             </p>
             <p>
              With penalties elevated over voluntary participation, the government's bill would bring us closer to the
              <a href="http://en.wikipedia.org/wiki/EU" rel="nofollow">
               EU
              </a>
              -style model of mandatory co-regulation. This approach sits at the halfway mark of approaches to this problem—on the lower end, non-regulatory approaches like digital literacy and fact checking; on the upper end, sometimes draconian anti-fake-news laws that can be misused by governments. Russia, for example, legislated to suppress media and political dissent about its war in Ukraine.
             </p>
             <p>
              Co-regulation, like that proposed in this bill, is not the same thing. Indeed, the core thesis of this proposal was coalition policy, and previously had bipartisan support. Ironically, since then the bill itself has arguably been the subject of disinformation, in the form of a knee-jerk reaction about freedom of expression. What those expressing concern need to answer is this: do they believe mis- and disinformation are a threat to democracy; and, if not this approach, what? This is absolutely a reasoned debate that is worth having.
             </p>
             <p>
              As a former journalist, I believe wholeheartedly that freedom of expression is central to a healthy democracy. At the centre of the bill under discussion today is the fact that it is not the government, but the platforms, that would remain responsible for their content. New powers would allow
              <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
               ACMA
              </a>
              access to a platform's procedures to see how it deals with online mis- and disinformation that can cause serious harm, and to request changes to processes, not content. ACMA would not be given arbitrary powers to determine what content is true or false nor to have posts removed. Australia has had a voluntary code along these lines since 2021, but not everyone opts in. Platform participation with registered codes would be compulsory and attract warnings, fines and penalties for noncompliance, but the definitions of mis- and disinformation in this bill may be too broad, and excluding government information and online news media content is also questionable. This is an uncomfortable but necessary conversation, and any legislation must be carefully calibrated to help rebuild, not further erode, public trust. I say: don't bin the bill; fix the bill.
             </p>
             <p>
              6:11 pm
             </p>
             <a name="g230.1">
             </a>
             <p class="speaker">
              <a href="/mp/?m=736" title="See more information about Josh Wilson">
               <img alt="Photo of Josh Wilson" class="portrait" src="/images/mps/10893.jpg"/>
               <strong>
                Josh Wilson
               </strong>
              </a>
              <small>
               (Fremantle, Australian Labor Party) |
               <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                Hansard source
               </a>
               <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.230.1&output=js-link"></script> -->
              </small>
              <p>
               Another day, another relatively hollow debate courtesy of the coalition, who've decided that their approach to parliament and public debate will be characterised by negativity and sometimes hypocrisy, when the Australian people have made it pretty clear that they're sick of divisive and obstructive politics. Before the 2022 election, the former communications minister said:
              </p>
              <p class="italic">
               The Morrison Government will introduce legislation this year to combat harmful disinformation and misinformation online.
              </p>
              <p>
               As I understand it, the Liberal Party website to this day says:
              </p>
              <p class="italic">
               … a re-elected Liberal Coalition Government will introduce stronger laws to combat harmful disinformation and misinformation online by giving the media regulator stronger information-gathering and enforcement powers.
              </p>
              <p>
               That valid intention was informed by the 2019
               <a href="http://en.wikipedia.org/wiki/ACCC" rel="nofollow">
                ACCC
               </a>
               inquiry into digital platforms, and yet here we are tonight: the coalition come along, as they do on most days, and carry on as if an exposure draft of a bill that seeks to advance exactly the kinds of protection that the coalition itself had pledged to deliver is some kind of outrage.
              </p>
              <p>
               You might think there would be some acknowledgement in the motion that this is one of the dozens of areas in which the coalition, after a decade in government, did nothing, but there isn't. It's disappointing that there isn't more calm and semireasonable preparedness by the coalition to be constructive about the task at hand. Instead, we get sloganeering and negativity—'bin the bill'—in relation to a bill that hasn't actually been introduced to the parliament. And the notice of motion, as the previous speaker noted, doesn't contain anything that might suggest the coalition has given thought to solving the problem, which they identified but did nothing about.
              </p>
              <p>
               There's no question Australia needs up-to-date and fit-for-purpose protection when it comes to the potential for serious and harmful misinformation, particularly through digital platforms that are operated by massive, foreign owned tech companies. But let me be clear about my fundamental view on this: any regulation of speech and public conversation needs to be done with great care. Any regulation of speech and public conversation needs to keep freedom of speech and freedom of association as its touchstone.
              </p>
              <p>
               The reason you have an exposure draft process is so that input can be provided and improvements can be considered. That's what's occurred in the life of this parliament to date in lots of areas, but often without much participation from the coalition—in fact, in some cases it occurred despite them. The government has worked hard to begin advancing all those things that didn't occur over the previous ten years: action on climate change, integrity improvements, repairing the social safety net, putting downward pressure on energy prices, getting wages moving again, and investing in social and affordable housing. But none of those carefully measured solutions have involved the input of the coalition, who just want to say no to everything.
              </p>
              <p>
               Even with our central and abiding commitment to free speech, we know there are certain kinds of communication that need to be regulated. There's plenty of conversation and information that might be controversial or represent different political views or even present strange, unpopular, obnoxious or hard to like ideas. All of that is still deserving of protection as part of a healthy and diverse public square discussion. But we know that some information is disseminated with the intention of doing harm, advocating hate or violence, facilitating the abuse of children, interfering in elections or doing harm in critical areas like public health.
              </p>
              <p>
               We must have the means in Australia of protecting our democratic system and our shared wellbeing from intentionally dangerous and harmful disinformation and misinformation. That's why the government has picked up the work that the previous government didn't do, by producing an exposure draft of a bill that seeks to build on the industry's existing voluntary code. What does it seek to achieve? Hey presto, surprise, surprise! Greater transparency from the big tech platform operators, greater compliance with the commitments that are already in the industry code and systemic improvements when it comes to managing and responding to complaints.
              </p>
              <p>
               It doesn't give
               <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                ACMA
               </a>
               the power to remove content. It strengthens the expectations on the industry itself and the clarity and accountability around those expectations. It strengthens the regulator's ability to act and enforce standards. That is at the core of what's needed in this space: sensible standards and mechanisms to be able to respond to the harmful and dangerous misuse of the enormous influence that exists through digital platforms, while, of course, protecting free speech and robust debate.
              </p>
              <p>
               If the coalition wants to engage in a sensible and constructive fashion about how to refine and settle an effective framework, that would be very welcome. But all that this notice of motion has shown in the debate tonight is that we're going to keep getting relentless, relatively pointless negativity from a group of people that promised all sorts of things for 10 years and did absolutely nothing.
              </p>
              <p>
               6:16 pm
              </p>
              <a name="g231.1">
              </a>
              <p class="speaker">
               <a href="/mp/?m=802" title="See more information about Keith Wolahan">
                <img alt="Photo of Keith Wolahan" class="portrait" src="/images/mps/10990.jpg"/>
                <strong>
                 Keith Wolahan
                </strong>
               </a>
               <small>
                (Menzies, Liberal Party) |
                <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                 Hansard source
                </a>
                <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.231.1&output=js-link"></script> -->
               </small>
               <p>
                We have lots of motions come into this place, and some are more important than others. This is about as important as it gets because it refers to a fundamental right, which is freedom of speech. Without freedom of speech, we don't have any of the other rights. That is the right from which the others flow. If it is compromised, all of the others are, including democracy.
               </p>
               <p>
                We also see, in a lot of these motions and the response to them, a political syllogism where we identify a problem that we can all agree on and we say: 'Well, someone must do something.' Then a bill is presented: 'Well, this is something, therefore we must do that. And if you don't support that, then you're not with us on agreeing to do something about it.' The problem is that when a bad bill is presented, you either amend it or you throw it out. And this one is so bad it must be binned. There's no reworking this one, as many other members have said. It is fundamentally, in its structures and its definitions, flawed.
               </p>
               <p>
                We saw the member for Warringah refer to the practice in the courts for 'misleading and deceptive conduct.' I've conducted trials with that section. It's section 18 of the Australian Consumer Law. It is one of the most litigated sections in Australian law. I've been in trials that have gone for over 100 hearing days. They've been before the courts for years, with multiple millions of dollars spent interpreting those words, 'misleading and deceptive.' They sound simple but in practice they're not. With a bill like this, the hard reality of trying to solve a problem that sounds simple is that we must recognise that the solution can be worse than the problem that you think you're trying to fix.
               </p>
               <p>
                When we look at the various groups that have put submissions into this draft exposure bill, none of them have been published. We had an excellent submission by the
                <a href="http://en.wikipedia.org/wiki/Victorian_Bar" rel="nofollow">
                 Victorian Bar
                </a>
                . The Victorian Bar didn't do a submission on the draft Voice position, but the government was quite happy to claim that a vote by its members was great. They've put pen to paper on this particular bill. You can't pick and choose when you're going to listen to an organisation. It's the same with the Law Council. They've given a very concerning submission, where they've said that the prospect that digital platform providers and
                <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                 ACMA
                </a>
                will be required to sift information from opinion or claims is, in itself, likely to have a chilling effect on freedom of expression. Again, you can't pick and choose when you listen to groups like the Law Council, because this bill is deeply flawed. Even the media union, the
                <a href="http://en.wikipedia.org/wiki/MEAA" rel="nofollow">
                 MEAA
                </a>
                , have criticised it, and they have thousands of members who work in this sector. Will Labor listen to one of its own unions which actually works in this area?
               </p>
               <p>
                This will, in its current draft, create a lawyer's picnic. One of the questions that anyone will ask is: what is excluded content? There are enormous carve-outs within this provision. We've heard many members, including the member for Goldstein, talk about the rise of
                <a href="http://en.wikipedia.org/wiki/Donald_Trump" rel="nofollow">
                 Donald Trump
                </a>
                , saying that they saw it firsthand and that we could have our own 6 January moment. Guess what: in this bill, if President Trump held office here, he'd be excluded. He's not covered. He gets a free pass, but no-one mentions that. That's the problem with this: it creates a status of opinion. So an Australian President Trump is fine, but a man, woman, boy or girl on the street is not fine. That's totally unacceptable, but that's the way this has been put.
               </p>
               <p>
                Then there is the way it links even the slightest bit of misinformation. It says that it's 'reasonably likely to cause or contribute to harm'. So, if there's a paper or post that's been written and there's one sentence or one line could cause or contribute to harm, that would mean that it could be censored. Again, we've heard from the government that ACMA, won't be doing that; they'll just be creating a regime for the tech companies to do it. They are in the business of making money and they're going to be extra cautious. They don't have the time or the staff to sift through these, so you're going to purchase off-the-shelf an
                <a href="http://en.wikipedia.org/wiki/AI" rel="nofollow">
                 AI
                </a>
                program that will sift through as much information as possible so it doesn't bring you before the wrath of ACMA.
               </p>
               <p>
                Then, in all of the other carve-outs, what does 'news content' mean? What does 'academia' mean? And why should politicians, journalists and professors get a free pass? We should all be subject to the same free-speech laws.
               </p>
               <p>
                6:21 pm
               </p>
               <a name="g232.1">
               </a>
               <p class="speaker">
                <a href="/mp/?m=784" title="See more information about Carina Garland">
                 <img alt="Photo of Carina Garland" class="portrait" src="/images/mps/10972.jpg"/>
                 <strong>
                  Carina Garland
                 </strong>
                </a>
                <small>
                 (Chisholm, Australian Labor Party) |
                 <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                  Hansard source
                 </a>
                 <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.232.1&output=js-link"></script> -->
                </small>
                <p>
                 At the heart of this motion, really, is a conversation about our democracy and, of course, the need to balance the freedom of expression with preserving and protecting our precious democracy. It is really important to note that democracy is precious in our world, and we've seen too many jurisdictions where people have taken for granted the fact that there is a stable democracy. Unfortunately, we've seen too many examples of places where misinformation and disinformation have undermined the institutions that we really should be protecting in our parliaments and our governments. We should also be protecting the right for people to freely exercise their expression and their right to make decisions about really important things like who will govern them.
                </p>
                <p>
                 We know misinformation and disinformation threaten the safety and wellbeing of Australians. We see, with online platforms, that this misinformation and disinformation are spread at speed and scale, and the impact of these harmful campaigns are felt offline too. Left unchecked, our democracy, society and economy are at risk—and I don't think that's overstating things at all. We know that, according to the
                 <a href="http://en.wikipedia.org/wiki/Australian_Communications_and_Media_Authority" rel="nofollow">
                  Australian Communications and Media Authority
                 </a>
                 , most Australians are concerned about, and have experienced, online misinformation. I have certainly encountered this, as I am sure other people in this place have too. We know that disinformation campaigns have the potential to undermine our national security and the integrity of our democracy.
                </p>
                <p>
                 In August 2023, a bipartisan final report of the Senate Select Committee on Foreign Interference through Social Media was tabled. On the risk posed to Australia's democracy by foreign interference through social media, it said:
                </p>
                <p class="italic">
                 … targeted online disinformation campaigns that leverage social media platforms to skew public debate, undermine trust in our democratic institutions, and establish narratives that favour the interests of authoritarian states.
                </p>
                <p>
                 The fact is that social media and digital platforms—often private, overseas based companies—already do take down misinformation and disinformation content at scale every day. Some, but not all, platforms have signed up to a voluntary, self-regulatory code of practice that was developed by industry to respond to the threat of misinformation and disinformation.
                </p>
                <p>
                 This exposure draft, which has been referred to through the debate tonight, builds upon this work. It builds upon industry's self-regulatory code of practice, as well as key recommendations made by the
                 <a href="http://en.wikipedia.org/wiki/ACCC" rel="nofollow">
                  ACCC
                 </a>
                 , in its 2019 Digital Platforms Inquiry, and
                 <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                  ACMA
                 </a>
                 , in its June 2021 report to government on the adequacy of platforms' disinformation and news quality measures. This bill empowers the Australian regulator to apply greater transparency from big tech, to encourage compliance with industry codes and to require systemic improvements by industry when necessary, such as in relation to complaints handling processes.
                </p>
                <p>
                 This bill does not empower ACMA to take down individual pieces of content. Digital platforms will continue to be responsible for the content on their platforms.
                </p>
                <p>
                 I find it truly remarkable, and of course ironic, that in a debate on misinformation and disinformation we've heard so much of both of those things from those opposite this evening. What our government is trying to do here is balance freedom of expression with the need to protect democracy, and I would have thought that's something that everyone in this place could agree is a good thing to do. Unfortunately, however, those opposite are taking this issue and cynically using it to score cheap political points by exploiting people's fears. They're all over the shop on this issue. Where we would have hoped they'd work constructively on this issue to address seriously harmful misinformation and disinformation that threatens Australians and our democracy, we see what we're seeing tonight, which is a lot of misinformation pedalled despite the fact that at the last federal election the coalition went to the election saying they would introduce a bill to empower ACMA to address misinformation and disinformation. So it's really important we call this cynical attempt out for what it is, which is just an attempt to score cheap political points at the expense of our democracy.
                </p>
                <p>
                 6:26 pm
                </p>
                <a name="g233.1">
                </a>
                <p class="speaker">
                 <a href="/mp/?m=783" title="See more information about Aaron Violi">
                  <img alt="Photo of Aaron Violi" class="portrait" src="/images/mps/10971.jpg"/>
                  <strong>
                   Aaron Violi
                  </strong>
                 </a>
                 <small>
                  (Casey, Liberal Party) |
                  <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                   Hansard source
                  </a>
                  <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.233.1&output=js-link"></script> -->
                 </small>
                 <p>
                  There's no doubt that misinformation and disinformation is a significant risk to our democracy, and those on this side of the House have never said otherwise. As I have said recently, with the uptake of
                  <a href="http://en.wikipedia.org/wiki/AI" rel="nofollow">
                   AI
                  </a>
                  we are losing the ability to trust what we see and what we hear, and that's significant. But, just because this risk exists, it doesn't mean we are going to support a deeply flawed piece of legislation—so flawed that it has been opposed by almost everyone, from the Human Rights Commission; the Media, Entertainment and Arts Alliance; the
                  <a href="http://en.wikipedia.org/wiki/Law_Council_of_Australia" rel="nofollow">
                   Law Council of Australia
                  </a>
                  ; civil liberty groups; and everyday Australians in my electorate of Casey and many electorates across the country.
                 </p>
                 <p>
                  I've had many people contact my office concerned about the implications this bill will have on freedom of speech, democratic rights and individual thought. To those people I would say this: the Liberals will not be supporting this bill. Those of us on this side of the House believe in freedom of thought, worship, speech and association. We believe in a less government interference in our daily lives, not more.
                 </p>
                 <p>
                  This bill defines misinformation as 'a statement which is unintentionally false, misleading or deceptive'. Let's have a think about that for a second. How often do Australians make statements that they believe to be true but turn out to be false? We're not experts at everything but, under this definition, Australians will be held to account for statements they make being unintentionally wrong. Under this legislation, if the regulator
                  <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                   ACMA
                  </a>
                  thinks digital companies like Facebook and Instagram aren't doing enough to remove that sort of content and if they think it's capable of what the government calls 'serious harm', those digital companies can get fines worth $6.88 billion or five times their annual turnover. So what are the digital companies going to do? They're going to remove posts from their platforms to mitigate the risks of fines, tarnishing Australians' rights to freedom of speech.
                 </p>
                 <p>
                  Under Labor's plan, there will be one rule for
                  <a href="http://en.wikipedia.org/wiki/Anthony_Albanese" rel="nofollow">
                   Anthony Albanese
                  </a>
                  and his government and another for everyone else. Information authorised by the government cannot be deemed misinformation. Criticisms of the government by Australians however can be deemed misinformation and therefore are at risk of being removed from public debate on digital platforms. And it doesn't end there. Nothing an academics says can be misinformation, but statements by somebody disagreeing with that academic can be misinformation. Good faith statements made by comedians and entertainers cannot be misinformation, but good faith statements made by Australians on political matters are misinformation. What we can potentially see is the Labor Party or future governments using the term 'misinformation' to try to silence those who do not share their political views, and this is a dangerous proposition in a free society.
                 </p>
                 <p>
                  Just last week in question time, we saw Minister Burke criticise and label an ad voicing opposition to Labor's industrial relations bill as 'misinformation'. Under this legislation Minister Burke could ban that ad.
                  <a href="http://en.wikipedia.org/wiki/Anne_Twomey" rel="nofollow">
                   Anne Twomey
                  </a>
                  , a constitutional expert, in the
                  <i>
                   Australian
                  </i>
                  today, said:
                 </p>
                 <p class="italic">
                  I mean there is a serious risk that in combating misinformation and disinformation we seriously undermine freedom of speech, which is a pillar of that system of democracy that we're trying to defend. … we might actually make the situation even worse than the problem that we're trying to cure.
                 </p>
                 <p>
                  And the Human Rights Commissioner, Lorraine Finlay, has published a powerful submission to the government on this legislation, saying the bill risks 'enabling unpopular or controversial opinions or beliefs to be subjectively labelled as misinformation or disinformation and censored'.
                 </p>
                 <p>
                  As I said, we acknowledge the risk of misinformation and disinformation, but a deeply flawed bill has implications for free speech for our democratic society, and that is why this motion is so important. We've seen time and time again the risk in other countries. We can't allow that risk in our country.
                 </p>
                 <p>
                  6:32 pm
                 </p>
                 <a name="g234.1">
                 </a>
                 <p class="speaker">
                  <a href="/mp/?m=697" title="See more information about Mike Freelander">
                   <img alt="Photo of Mike Freelander" class="portrait" src="/images/mps/10872.jpg"/>
                   <strong>
                    Mike Freelander
                   </strong>
                  </a>
                  <small>
                   (Macarthur, Australian Labor Party) |
                   <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                    Hansard source
                   </a>
                   <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.234.1&output=js-link"></script> -->
                  </small>
                  <p>
                   I'm actually very troubled that the shadow minister for communications is willing to move a motion attacking a minister and her department who are trying to take strong action against one of the most serious national security threats that we have in this country. We've just recently marked the anniversary of the Optus hacking scandal, which was a difficult time for many people, but through the guidance of our government and relevant stakeholders, we're taking tough and appropriate action to protect our national security and our democracy.
                  </p>
                  <p>
                   We've just come through the most gruelling pandemic in our national history where we saw the threat of disinformation and misinformation to public safety, including ridiculous suggestions that drinking or injecting bleach can safely treat a viral infection. This really worried me during the last parliament, and I did call out the previous member for Dawson and the previous member for Hughes, who were desperate for media attention, and as such, instituted a program of disinformation that reached the widest area of our country. False and misleading information about the pandemic, such as how to prevent exposure, possible treatments and the origins of the virus have been shown to have real-world consequences, including personal illness, damage and death. I certainly saw that in my electorate, where people were so frightened by the disinformation that they denied themselves appropriate treatment and died.
                  </p>
                  <p>
                   I called out the previous government for this. They were essentially silent on the issue. It's an absolute tragedy that we are still seeing members of this parliament distributing so much disinformation, including one senator in this place who has distributed a number of CDs and lectures on public health that are clearly false, that are clearly misleading and that are doing irreparable harm to our public health policies. This is still happening in this parliament, and it needs to stop.
                  </p>
                  <p>
                   Only two years ago, here, in this parliament, the member for Hughes used his position and his media platforms to dispense nothing but lies and false hope, all for his own gain and our pain. Too many members and senators of this parliament have abused their privileged roles to spread lies about COVID vaccines, lockdowns and management. A United Australia senator from Victoria has used the parliament's mail system and the MPs' communication budget to send ridiculous, deliberately misinformed thumb drives and CDs about COVID vaccines throughout the parliament and to a wider audience in the community. The mis- and disinformation within these very walls, at the highest levels of Australian politics, has been a tragedy, and when the shadow minister comes out and attacks the Minister for Communications through this motion, I must ask him: Where does the opposition sit when it comes to mis- and disinformation? Are they happy for this to be distributed? Do they really want this to continue?
                  </p>
                  <p>
                   The previous minister for communications, the current member for Bradfield, was going to act on this very issue, and in very similar fashion, yet now the coalition—or the 'no-alition'—sees this proposed bill as a major issue. Since when? They're reinventing themselves. This was highlighted by Paul Karp of the
                   <i>
                    Guardian
                   </i>
                   in July this year, when he noted that the coalition went to the May 2022 election with a promise to introduce new laws to hold big tech companies to account. They never did, of course. Since when has national security and the need to tackle disinformation been a partisan issue? I am a parent and I'm a grandparent, and I am worried what my children and grandchildren are being exposed to online. They live online. It's different. It's a generational change that we need to deal with, and anyone who thinks that we don't is crazy.
                  </p>
                  <p>
                   This draft bill does not empower
                   <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                    ACMA
                   </a>
                   to take down individual pieces of content. Digital platforms will continue to be responsible for the content on their platforms. The shadow minister's motion demonstrates that he misunderstands the bill, because a number of the points he raises are completely incorrect. We need to do this. We need to do this for future generations. It is very important, and this parliament needs to act now.
                  </p>
                  <p>
                   6:37 pm
                  </p>
                  <a name="g235.1">
                  </a>
                  <p class="speaker">
                   <a href="/mp/?m=744" title="See more information about Pat Conaghan">
                    <img alt="Photo of Pat Conaghan" class="portrait" src="/images/mps/10922.jpg"/>
                    <strong>
                     Pat Conaghan
                    </strong>
                   </a>
                   <small>
                    (Cowper, National Party, Shadow Assistant Minister for Social Services) |
                    <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                     Hansard source
                    </a>
                    <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.235.1&output=js-link"></script> -->
                   </small>
                   <p>
                    In Australia we live in a free and equal society, or at least that's what governments over the past 100 years have striven to achieve for all their citizens. Freedom to form our own opinions, freedom to seek information and freedom to ask questions are all tenets of a democratic society, yet this bill seeks directly to negate that. As members of the National Party, we maintain a strong sense of central values. These include the preservation of the rights of the individual and equality of opportunity for all; the preservation of freedom of the press, radio, television and means of communication; the preservation of freedom of speech; and the strong belief that governments should provide a framework for individual growth, not control.
                   </p>
                   <p>
                    This bill flies directly in the face of these values. These aren't just National Party values; these are the values of everyday, ordinary Australians. Not only does it threaten freedom of speech; it assigns government as the ultimate approver of all information that is classified a fact. This mirrors the ideals of some communist countries or those under dictatorship. It is not what we, as a federal government or as a country, aspire to. Of grave concern is the fact that the definition of 'misinformation' is so broad that it could capture almost any statement made by Australians in the context of political debate, and the government of the day, as the ultimate deciders of what is classified as 'misinformation', can effectively censor those who disagree with them.
                   </p>
                   <p>
                    This bill is literally giving licence to any government—and I warn the other side: any government—who disagrees with them. The bill is literally giving power for information. It is a terrifying thought. And that's not just my opinion or that of my colleagues. This is the opinion of the Human Rights Commissioner, civil liberties groups, the
                    <a href="http://en.wikipedia.org/wiki/Law_Council_of_Australia" rel="nofollow">
                     Law Council of Australia
                    </a>
                    and the media union—the very bodies that advise the federal government when it is forming policy. How can we now ignore these important institutions? On one hand, this government is obsessed with forming a lobby advisory body and labelling it 'the Voice', while on the other hand it completely ignores existing advisory bodies and seeks to silence the voices of all Australian citizens. The Human Rights Commission's submission states:
                   </p>
                   <p class="italic">
                    … there are examples around the world of information being opportunistically labelled as 'misinformation' or 'disinformation' to delegitimise alternative opinions and justify censorship.
                   </p>
                   <p>
                    Commissioner Lorraine Finlay further offers the concern that the bill:
                   </p>
                   <p class="italic">
                    … risks enabling unpopular or controversial opinions or beliefs to be subjectively labelled as misinformation or disinformation, and censored as a result.
                   </p>
                   <p>
                    The exclusion of authorised government content from being deemed as misinformation:
                   </p>
                   <p class="italic">
                    … fails to acknowledge the reality that misinformation and disinformation can come from government.
                   </p>
                   <p>
                    These are direct quotes from the very commission the government is obligated to submit each piece of legislation to—the gatekeepers of our Australian human rights.
                   </p>
                   <p>
                    As a former lawyer, I am personally well accustomed to taking direction from the Law Council of Australia. They echo the concerns submitted by the Human Rights Commission and go a step further, stating:
                   </p>
                   <p class="italic">
                    The risk is that disfavoured opinions might come to be labelled and regulated as 'misinformation' …
                   </p>
                   <p>
                    Words and definitions matter. There is no body more acutely aware of this than the Law Council of Australia.
                   </p>
                   <p>
                    I will conclude with a quote from a message
                    <a href="http://en.wikipedia.org/wiki/Harry_S_Truman" rel="nofollow">
                     Harry S Truman
                    </a>
                    delivered to Congress in August 1950. He said:
                   </p>
                   <p class="italic">
                    Once a government is committed to the principle of silencing the voice of opposition, it has only one way to go, and that is down the path of increasingly repressive measures, until it becomes a source of terror to all its citizens and creates a country where everyone lives in fear.
                   </p>
                   <p>
                    6:42 pm
                   </p>
                   <a name="g236.1">
                   </a>
                   <p class="speaker">
                    <a href="/mp/?m=747" title="See more information about Daniel Mulino">
                     <img alt="Photo of Daniel Mulino" class="portrait" src="/images/mps/10925.jpg"/>
                     <strong>
                      Daniel Mulino
                     </strong>
                    </a>
                    <small>
                     (Fraser, Australian Labor Party) |
                     <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                      Hansard source
                     </a>
                     <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.236.1&output=js-link"></script> -->
                    </small>
                    <p>
                     The World Economic Forum has ranked the spread of misinformation as among the world's top risks. There are numerous reasons we need to act on misinformation and disinformation. Both have real-world dangers. These include consequences for public health and safety, for social cohesion and for electoral integrity—and, therefore, for democracy itself. False, misleading and deceptive content has always been with us. The difference now is that where a myth used to be spread amongst just a few people, social media has magnified this risk and can spread it a thousandfold or more. As Tim Berners-Lee, the father of the internet said:
                    </p>
                    <p class="italic">
                     While the web has created opportunity, given marginalized groups a voice, and made our daily lives easier, it has also created opportunity for scammers, given a voice to those who spread hatred, and made all kinds of crime easier to commit.
                    </p>
                    <p>
                     We saw during the COVID pandemic the deadly consequences of misinformation and disinformation, as people turned to treatments such as drinking or injecting bleach or drinking alcohol based cleaning products. In the
                     <a href="http://en.wikipedia.org/wiki/US" rel="nofollow">
                      US
                     </a>
                     , misinformation had severe public health consequences, often undermining efforts to contain the spread and impact of COVID-19, for example. Misinformation about vaccines continues to pose significant health risks. When he was head of the
                     <a href="http://en.wikipedia.org/wiki/NHS" rel="nofollow">
                      NHS
                     </a>
                     in the
                     <a href="http://en.wikipedia.org/wiki/UK" rel="nofollow">
                      UK
                     </a>
                     , Simon Stevens said misinformation from antivaxxers on social media had fuelled a tripling of measles cases in the country.
                    </p>
                    <p>
                     The cost of misinformation and disinformation in the electoral sphere is incalculable. A
                     <a href="http://en.wikipedia.org/wiki/Brookings_Institute" rel="nofollow">
                      Brookings Institute
                     </a>
                     paper found that misinformation is eroding the public's confidence in democracy. Meanwhile, the
                     <a href="http://en.wikipedia.org/wiki/Australian_Human_Rights_Commission" rel="nofollow">
                      Australian Human Rights Commission
                     </a>
                     has noted that misinformation is one of the three particular risks to democracy and human rights in Australia.
                    </p>
                    <p>
                     Claims that the proposed changes amounts to censorship misunderstand the operation of the bill, and the fact that digital platforms are responsible for the content on their platforms.
                     <a href="http://en.wikipedia.org/wiki/Social_media" rel="nofollow">
                      Social media
                     </a>
                     and digital platforms—private, overseas based companies—already take down misinformation and disinformation content, at scale, every day. Some platforms have signed up to a voluntary self-regulatory code of practice that was developed by industry to respond to the threat of misinformation and disinformation. But voluntary codes have shortfalls. Not all platforms participate, and some cherry-pick the areas of the code that they will respond to. That's why a mandatory, co-regulatory approach is important.
                    </p>
                    <p>
                     The definition of misinformation covers content which is false, misleading or deceptive, which is likely to cause, or contribute to, serious harm, and which is provided on a digital service and spread at scale. It includes content disseminated with intent to deceive, including purposefully or maliciously disseminated information. The definition sets a high bar because of its serious harm threshold. The government is not ruling what information is false. The
                     <a href="http://en.wikipedia.org/wiki/Australian_Communications_and_Media_Authority" rel="nofollow">
                      Australian Communications and Media Authority
                     </a>
                     would not have powers to determine what content is true or false or direct that specific posts be removed. Digital platforms will continue to be responsible for the content on their services. The content of private messages, authorised electoral communications, parody and satire, and news media remains outside the scope of the proposed changes.
                    </p>
                    <p>
                     The bill is about transparency, and, importantly, it is about systems and processes.
                     <a href="http://en.wikipedia.org/wiki/ACMA" rel="nofollow">
                      ACMA
                     </a>
                     would be able to check how a platform deals with online misinformation and disinformation that can cause serious harm and would be able to request changes to processes. The bill empowers the regulator to require greater transparency from big tech, to encourage compliance with industry codes and to require systemic improvements by industry where necessary, such as in relation to complaints-handling processes. As the former chair of the
                     <a href="http://en.wikipedia.org/wiki/ACCC" rel="nofollow">
                      ACCC
                     </a>
                     Rod Sims said, governments face two choices on these vital but difficult issues: do nothing and leave it to the platforms to decide whether to do anything at all or seek to intervene in some way.
                    </p>
                    <p>
                     While the shadow minister has nothing more than a three-word slogan—'In the bin'—the Albanese government will not resile from holding big tech to account and keeping Australia safe online.
                    </p>
                    <a name="g236.10">
                    </a>
                    <p class="speaker">
                     <a href="/mp/?m=739" title="See more information about Bridget Archer">
                      <img alt="Photo of Bridget Archer" class="portrait" src="/images/mps/10917.jpg"/>
                      <strong>
                       Bridget Archer
                      </strong>
                     </a>
                     <small>
                      (Bass, Liberal Party) |
                      <a href="http://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;adv=yes;orderBy=_fragment_number,doc_date-rev;page=0;query=Dataset%3Ahansardr,hansardr80%20Date%3A11%2F9%2F2023;rec=0;resCount=Default" title="The source of this piece of text">
                       Hansard source
                      </a>
                      <!-- | <script type="text/javascript" src="http://parlvid.mysociety.org/video.cgi?gid=2023-09-11.236.10&output=js-link"></script> -->
                     </small>
                     <p>
                      There being no further speakers, the debate is adjourned, and the resumption of the debate will be made an order of the day for the next sitting.
                     </p>
                     <br/>
                     <br/>
                     <br/>
                     <br/>
                     <div id="footer">
                      <p>
                       <a href="/?show_pc">
                        View the PC OA website
                       </a>
                      </p>
                     </div>
                    </p>
                   </p>
                  </p>
                 </p>
                </p>
               </p>
              </p>
             </p>
            </p>
           </p>
          </p>
         </p>
        </p>
       </p>
      </p>
     </div>
    </div>
   </div>
  </div>
 </body>
</html>
