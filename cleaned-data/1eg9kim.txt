
Australian universities long ago gave up excellence and chased the cash. Standards are falling and the executive are more concerned about their renumeration than actually managing.  It's a chase for enrolments which equals money. They don't care how many students fail or the horrendous HELP debts being accumulated.  A total disgrace.
I'm a casual teacher at an Australian university, and you can see when students are using AI. Not always, but most of the time. 

It's a great tool when used appropriately, but students do silly things when stressed and time poor. The sad thing is, they won't learn from using ChatGPT as a quick answer. Worst, we don't have surefire ways of proving they used AI, so we can't threaten with academic misconduct. 

After reading so many papers, you learn to spot AI language use. It's so obvious. Yet I'm powerless to stop them. It's shit.
Oh, the integrity of Australia's universities is at risk, is it?
I remember losing 10% on an essay I wrote at university circa 2018 because I didn‚Äôt attribute a source correctly. I did reference the source, but I used it word-for-word‚Äîbasically a direct quote, and I didn‚Äôt use quotation marks. How quickly standards have fallen. I graduated in 2020 and I‚Äôm glad I got out of uni when I did.¬†
I went back to uni this year..... last time I was there in 99-2002, fuck me what a change...It is basically impossible to fail, the amount of help you get is INSANE! Maybe it's cause it's the University of Tasmania...but yeah the ability to send off your essays to be checked by a third party then they say where you are going wrong, fix references etc. Then you are good to go! All this access is approved and free for students.
Australian universities are a backdoor immigration system.
I was in a Master's degree for a Uni in Australia. Doing Professional Accounting. Got put into a random computer science class where I was told I could just use ChatGPT to do my assignment. That is the state of University now.
Something has got to change. There is no way of proving that someone is using chat gpt or the likes. Maybe more in person assignments? I'm not too sure.
Lol. Yes. Let's blame AI for why universities everywhere (not just Australia) are no longer the institutions of integrity they used to be.
Universities are nothing more than money printing sausage factories anyway. 

Product arrives, they pay money and products come out.

They are only complaining as it's impacting their bottom line.
AI of course is the issue but looking further into the problem, maybe showing that students are able to regurgitate information isn‚Äôt the best metric to test an understanding on a topic
Oh yes... this... ***this at last***... is what will put the integrity of Australian universities at risk.
It‚Äôs not so much a case of ‚Äúthis student cheated, but pass them so we can make money‚Äù but more a case of ‚Äúwe are fairly certain this student cheated but we have no way of proving it‚Ä¶‚Äù
But teachers can use AI to grade my paper and claim they read it themselves?
What integrity?
Maybe, just maybe, the unis will have to move to more meaningful assessment than getting students to write essays that they will never read again nor have any cause to write again once they have graduated...
Just look at All those nurses writing essays in between caring for patients!
It's not bad for all subjects. In Design we were encouraging students to use ChatGPT to help them write code. It not only generates code, but it explains how it works, and it nearly always has bugs, or at least something that needs changing, so it's a pretty good and fun way for students to learn programming.
AI is the least of their damn problems. 

You've got wildly unqualified people being admitted, you've got universities using English-speaking students to prop up students who don't speak the language, and hugely differing experiences/standards for HECs vs fee-paying students. 

Getting the academic integrity email used to be something so horrific and terrifying that it was told like a horror story. We'd be panicking if Turnitin came back with more than 15% matches. Now, it's treated with the annoyance of being reminded to change your password. "I used ChatGPT and got caught, how do I get out of this?" is a common message board question. 

Blaming AI is a fucking scapegoat. The universities need to own their fuck ups and start actually teaching - though I suspect the only people who would be held to any kind of accountability would be the HECs students.
Even before AI the amount of students putting ads up on Gumtree and airtasker was insane. It's big business helping these cheats.

Then you go into your chosen profession and it's so visible these people don't know a fucking thing. Now jobs are requiring proper "audition/ folio-like" experience making the whole degree kinda null and void in some professions.
Worked on a group assignment earlier this year and found out the day before it was due my group mate had used chat gpt for everything after I asked for sources. The person said, ‚Äúeveryone uses it, and they don‚Äôt check for sources‚Äù. After numerous nights trying to fix the crap work, and so stressed from carrying most of the workload, I flagged it to the lecturer. The response I got was ‚Äúthank you for respecting our institution‚Äù. Nothing further‚Ä¶ This uni claims to be in the top 50 in the world
Come up to the North Coast and you can experience this BUT in the air, flying a light aircraft, with the c\^nts coming head to head at you, whilst you are in the circuit or on short finals, without the correct or any radio frequency or any ability. The RPT guys are well over it. Thes 'pilots' get 225's but just seem to get magical dispensation and they disappear off their records, EVERY TIME. Using my aircrafts call sign to avoid landing fees shits me to tears, also. 

Not a sausage of English even when they do grace us with radio comms. These feckers are getting twin endorsement and will be flying freight/post in the future. Current Notams, where every strategic point and no fly zone is included free as part of the course.

And another thing if that prick steals my payed for, tie down parking space again, I'm may be forced to drag the Ex-hours Winjeel out and cut some fancy Pratt and Whitney 'speed and air intake grooves' down the side of his shiny new plane.  :)
Unpopular opinion: AI is here to stay.

Attempting to ban AI is like attempting to ban calculators, because "Real engineers do their own math!". Or spell-check, because "Real writers know how to write!"

The University curriculum and evaluation standards will have to adapt to the new reality that written expression alone does not constitute proof of understanding anymore, and introduce much more emphasis on defending the work in person.

There is nothing to be gained in attempting to bend the reality to obsolete expectations by ossified academia. They're supposed to be the thought leaders!

Those graduates will absolutely, positively, be required to use AI in their jobs. Because sooner or later, excessive manual writing will be seen as wasted effort, if a tool can do that for you. Just like not using calculator, MatLab or Excel, and doing calculations by hand, is now.
Was in a lab yesterday and literally watched the international student who hadn‚Äôt really done much in the lab put prompts into chatGPT to literally write his report for him, then he didn‚Äôt understand when I asked him ‚Äúwhere do you think this lens should be positioned‚Äù. Was not happy
It‚Äôs cute they think they still have integrity there lol
What ‚Äòintegrity‚Äô üòÇ
My tafe teacher actually told me to use it...
AI will hurt some areas but I'm much more concerned about pressure on professors to make their courses easier to lower the failure rates.
I find it hilarious because my wife is a student at an Australian university and we put some of the lecturers content into an AI checker and it came up as 90% AI generated or something similar. 

Meanwhile all of her assignments etc have to be submitted to an AI checker before being able to be submitted.
TAFE standards are ahead of uni at this point, getting my programming diploma I had to prove to my teachers that I understood and was capable of writing code, we were even taught how to use ai as a tool to learn from

having been to both uni and Tafe; I'd pick Tafe every time, fee-free and classes taught by people who are experienced within the industry
lol, technology is always going to be three or more steps ahead of institutions' slow and antiquated processes.

i think uni is mostly a scam except for a handful of degrees that are necessarily theory-heavy. Everything else, you can learn on the job and don't need a piece of paper for. Hell, even tafe would be better.

So the unis be playing the students as much as the students are playing the unis, if not more so.
I know someone at a top uni doing english language tuition for mainly Chinese students and chatgpt is used by some for every hand-in and sometimes secretly in exams despite invigilation, by some, and there is nothing they are allowed to do about it. If they fail because obvious AI use the exam or project, the student - who can barely string a sentence together - complains, and the poor mark gets overturned. So this is happening for students who clearly cannot produce the output they are getting scored on I bet for lazy students less obviously out of their depth its even easier to sail through any project while barely using their brains.
I think you need to be asked to present your assignments. You can use A.I to do your work, but if you can't explain the material or can't answer when quizzed,then you fail.
Shock horror when universities exist just to receive money from immigrants that pay their way through. 
We need free education for citizens and a refocus on education not profit. Immigration loopholes have degraded the quality of education in this country
All these articles... Am I the only honest student?
It's basically buying a degree for non-english speakers from overseas.

It used to be free for Australians, another monetisation boondoggle and wealth transfer scam.
I‚Äôm not surprised, I work with a lad who boasts all the time about how AI is gifting him a degree.
If universities didn‚Äôt have crisis meetings about this 2 years ago, then they deserve all they get.
I'm not in Australia any more, and my discipline should be less affected, but no one is going untouched. Graduate interviews over the next decade are going to be pretty brutal for the candidates -- at least until technical managers are ourselves replaced with robots by idiot accountants.
Lol what a farce the world has become
Would a shift to more of a focus on exams rather than assignments not address the majority of the issues with cheating?
Are we pretending that these graduates won't be using ai in their future jobs? 

Well if they are lucky to get a job in the first place
Wipe away all debt for all graduates pre AI because they should be compensated for actually doing the work at unnecessarily high fees.
its very notable that most of the "anti ai" tools are extremely flawed. grammerly and turnitin are by far the most flawed of the tools on offer and the only ones we use in Australian universities. and even openai's own detection tools report everything or nothing as ai. [https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00140-5](https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00140-5) with no in between.



its extremely difficult to detect and even worse the typical punishments are expulsion or failure.
I don't see a solution to this besides allowing AI for assignments and/or assessing through invigilated exams

Restricting AI is an arms race that universities and industry will never be able to win. There will come a point where AI-generated content can become indistinguishable from non-AI content - what is the solution then?
Traditional education is not keeping up. Evolve or die.
University is all about money - nobody gives a damn about cheating‚Ä¶just ask Julie Bishop, who left politics to ensure laws enabled universities to ‚Äòteach‚Äô thousands of kids who can‚Äôt speak English and give them degrees in return for cash‚Ä¶in return, she is well paid, and was able to spend $750K renovating her office, while the rest of the country can‚Äôt afford a can of corn soup.  My kids are at UNSW and when I ask if they make friends at uni they tell me most kids in their class can‚Äôt speak English well enough to have a conversation, they use GenAI and Google Translate for everything.  In group projects some of them don‚Äôt even bother to turn up, they just put their name in the group and get the group grade.
We‚Äôve been using it in graphic design to compile text into specific readable chunks which helps cuts down on formatting
I was in a group of 4 for a bachelor of business final assessment and the others all contributed to the piece at least 60-70% of their writing was AI. Their argument was ‚ÄòI did it for the rest of my assignments so it‚Äôs not a problem‚Äô. It‚Äôs going to cause a huge problem as many others in class when presenting clearly integrated AI without an ounce of original work. Lecturers / graders will still pass them though :)
Isn‚Äôt AI incredible?? ü§©
There‚Äôs really no way to know if people are using generative AI. I know some high school students who got called out for using Gen AI, but they didn‚Äôt.

All these academics and teachers should be subjected to a double-blind test to see if they can really determine if something was written by AI or a real person. My guess is that they won‚Äôt do a lot better than random chance.

The whole thing is a shit-show.
‚ÄúA humanities tutor at a leading sandstone university said she was ‚Äúdistressed‚Äù to find more than half of her students were flagged to have used AI in their first assignment for all or part of their work this year ‚Äì a ‚Äúhuge increase‚Äù on 2023.‚Äù

1. A fucking tutor is who they are interviewing?
2. Flagged? Not proven? ‚ÄúNobody is blind‚Äù to AI detectors being full of shit and not useful.

‚Äú‚ÄùSome of the cheating and plagiarism I have seen over the past 18 months is actually beyond belief,‚Äù one second-year undergraduate student said.‚Äù

How the fuck is a random student seeing other students papers? For 18 months? He started 18 months ago if he‚Äôs second year. Is he just asking to read everyone‚Äôs papers? Complete bullshit. 

This article is basically completely made up by people that have zero authority or zero facts and is just making numbers up.
The solution may just be to switch to the British system where 100% of your mark is dependent on a final written exam. It‚Äôs brutal but, hey, at least it‚Äôs difficult to cheat.
Uni's are already crap, so many students pay for their essays/assignments and other people to sit exams it's just a joke now ...
Australian universities have no integrity, don't know how many Chinese people I saw pass with 7s when they couldn't speak or understand one word of English.
No-one is talking about the shit doctors, nurses, lawyers, architects, engineers etc that will come out of these generations of uni students due to the greed of universities in Australia, and the government's 'need' for cheap, foreign student labour.

Remember folks - these will be the people looking after you in 10+ years, and building our infrastructure etc...

Frightening.
I mean I used ‚ÄúAI‚Äù for years on my assignments well before chatgbt lol. Nobody ever spotted it. Mostly just me typing shit out and getting programs to rewrite my awful comprehension.
Well, firstly, if you are doing a course which can be successfully completed by ChatGPT, you aren't really doing a course that requires intelligence; just the rote repetition of an approved answer.  Not suitable for a degree.

Second, stop with the emphasis on coursework done at home. Spot tests, in the university, to test actual understanding of the subject during the course.

Third, it wouldn't be difficult for external invigilators to enrol 'secret shoppers' to take the course and cheat - to see if they are ejected. Any course where they get passed, everyone is failed and the course shut down. Might concentrate everyone's minds.
The way academics talk about AI is legitimately paranoia though. If you look these keywords up on Twitter there are all kinds of tweets with academics sounding genuinely unhinged talking about students "cheating" in tenuous ways and claiming various words as "telltale" signs that someone has used AI to the point where the only way to make your writing sound "Not AI" is to be borderline illiterate. These students have researched, non plagiarised work, that complies with the rubric in every way but if it sounds too professional or they use too many three syllable words the academics will freak out "gotta be AI" with the implication being they strongly believe that their students are too dumb and uneducated to write comprehensibly in English. Heaven forbid someone use a grammar checker or something like that.
i‚Äôm low key glad i finished the majority of my cs degree before chatgpt got huge. i would have had the temptation to use it all the damn time
I work as a tutor and essay editor, about 80% of my students are ESL. I‚Äôve seen a massive decrease in students contacting me to work on an upcoming assignment, and a huge increase in students contacting me the day something is due because they‚Äôve got a ‚Äò78% AI detected‚Äô notice when they go to turn it in. I charge more for last-minute work, so it‚Äôs all the same to me, but I feel bad for the professors and the students are only short-changing themselves.
University should be like public schools.
Have all writing done in test conditions without access to tech.
What integrity? You're a business dammit. Paying customers aka. Students, regardless of how they got their grades or what grade they have, should be getting a degree regardless...

Until universities actually stop being a business and more of an institution, its a business and nothing more.
I would be concerned about the marker's ability if they can't tell AI writing from a real persons writing. AI is a cliche machine that doesn't actually have any creativity. Are we talking about people using AI to get C's so they pass without being able to actually write or know anything. This isn't excellence its enough to pass and to be honest it really shouldn't be able to pass with the current quality of AI writing.
Nah, they DO care how many fail. It's a good way to advertise:

"Come to our university, we're so good at teaching we have a 99% graduation rate!"

But then you find that the staff are all overworked and they're forced by admin to pass students who have handed nothing in just to keep those numbers up.
They have no choice. Federal governments have slashed funding massively over the last few decades. Universities need to make money somehow. If we don't want universities chasing money, we need to start reconsidering who we vote for.
Most universities are run like investment portfolio  property trusts.  Their prestige is related to the size of their property portfolio holdings which they pursue like property developers.

The University International ratings speak loudly automatically about our universities quality and prestige. These rankings have always been there and now that they have become degrees in  a cornflakes box sellers their prestige will slip even further. When it becomes widely known that the whole system is rotten nobody with sense buys the brand. Akin to buying fake merchandise where is the pride in that and what prestigious International company will buy into this fraud? Is it a wonder that many IT Education courses and certificates rank better in terms of employability compared to a legitimate IT degree.
100% accurate. The fact that anyone still thinks they have a calculable measure of integrity is a joke.
*renumeration - are you one of these students without a grasp on basic English?
It's wild how obvious it is when a student has copied a speech from a chat program. Speaking whilst barely knowing their own content.
[deleted]
The sad thing is, they pump out such mediocre analysis that the real answer is not in banning the is of LLMs. It's in raising marking standards to a point where GPT generated slop wouldn't pass anyway.  

But you'd *also* have to pair that with a change in how most courses are structured. A reduction in 500 word weekly responses to the reading material, and an increased focus on close reading would be a start.
I downloaded my lecture vids, transcribed using Whisper to a PDF and then used the PDF as source material for a super Google search engine.

I just wanted disability support but you have no not have a disability in order to navigate the hoops to get assistance.

I hope AI can make uni a bit fairer for individuals like me who just needed a bit more hand holding at times
I marked one the other day that still had the prompts in it but only had a 9% AI rating. I failed it because like most if these AI assignments it was shit. But I still had to mark it and fuck it hurt my brain.
The solution is to rejig assessments away from the generic essay format. Make the topic so specific (e.g., on a very local or niche issue) that an AI model can‚Äôt really discuss directly, then weight the criteria more heavily towards a critical take on that issue rather than shitting out generic information. It becomes very clear who has actually done digging and thinking vs those who are putting up surface level LLM text. 

Quite honestly I think this is good for learning in general. Essays are quickly becoming outdated in the modern age ‚Äî we need to be developing professional skills that will actually matter going forward. Filling a page with words is not one of those skills.
I get called out for it just because I use the word 'foster' a lot. I think I spoke like AI before AI popularised it. 

Thing is, I absolutely do use it - as a tool. Asking "What could this '-' question be asking me?' if i don't understand it. Lo and behold I know what I've misunderstood (usually obtuse question phrasing) and I'm off to read the books. Because y'know, the education part of the whole thing.
Same position a few TAFE lecturers are in I think from my recent experience, when they call students out the students file harassment claims.
[deleted]
Is there talk of going back to hand written and supervised assessments? Apart from a complete redesign of how things are taught and assessed this is the only way to stop the use of ai for cheating.
Laws need to catch up with the technology, I feel like by now we should have laws where AI have to mark their creations with code that can be easily found or that allows programs like Verbatim to collect data from different AI searches so when you submit your essay, it'll be checked on a database of AI answers.

I feel like solutions can be found that would at least solve the problem with the typical cheater using AI. Just need to make using AI reidiculously tedious.
>It's a great tool when used appropriately,

There's no appropriate use.
If you‚Äôre still getting paid and there‚Äôs no danger of you getting in trouble from failing to spot AI cheating, why would bother trying to catch it. It basically amounts to you doing extra work unpaid. Just let it slide and make your job easier.
[deleted]
It‚Äôs not just Australia. Declining academic standards for undergrads are an issue worldwide, including at *very* globally reputable universities
I graduated in 2011 from a Major University. Things were fucked up even back then. Rich overseas students were paying to get people to do assignments. They could barely converse with you at times, but great assignments still.
I remember as a first year being given a style guide for assignments that was like 10-15 pages long, and losing marks every instance you failed to follow it. A decade later I was doing some casual instruction with students who I suspect would've struggled to understand the style guide I was given, let alone adhere to it.
I have a feeling that would be forgiven if you were an upfront paying student.
Though that seems like a kind of problem you could have detected in advance with an LLM.
And in 2018, the same stories were running and people who graduated in 2008 were saying the same thing.
Ahh....no, bibliography and references, anxiety attack. I think I told one of my lecturers in a PHD, Geotechnics course to go and f\^ck themselves under similar circumstances a few years earlier.
That is definitely the uni you‚Äôre at. The uni I am at doesn‚Äôt have those services, we get told no drafts no external checking etc.
Lower ranked unis tend to have much better undergraduate support and education services
Thats program is good for helping you learn to write essays in first year, your proof reader points out obvious mistakes with gramme, spelling, syntax and formatting. They can help structure your argument too. That's easy marks in the first year at uni, but once you've developed those skills, the second year of uni ad beyond when you need to demonstrate critical thinking, this program isn't much of an advantage at all. I just see it as an equaliser for the students that didn't learn how to structure an argument in high school.
Depends on the teaching philosophy. Is university education supposed to be made achievable or not and for whom?
True, I see it constantly in our recruitment campaigns. Bachelor‚Äôs degrees from other countries, masters degrees from an Australian university. All applying with very well written resumes which are obviously drafted from professional resume drafters (all are close to the same formatting and similar language is used).  However, any interaction outside of these pre written documents demonstrates terribly broken language skills.
Maybe it kinda makes sense. It's a tool, and if you can successfully use that tool to do the things you need to do, then what's the issue? Most programmers will tell you that half their work is just googling to find out how other people did the thing they're trying to do. Telling students not to use ChatGPT when you have no way to detect it just disadvantages the honest people. Give them challenges with the assumption that they will use every tool at their disposal and grade them on that, because that's what they'll be doing in the real world.
pre chat gpt guess what you were doing as a programmer or someone in IT? googling solutions on stackoverflow and geeksforgeeks. chatgpt makes this process a lot faster, but to be thorough you obviously have to verify your answer either by already being educated on the subject or validating the output with reliable sources
Invigilated assessments and real-time oral defenses are the most reliable methods. Even these can be cheated with some effort, such as hiring someone to stand in for you, and neither can be effectively done remotely. They also require a lot more time from the tutors since someone has to actually watch you.

In a way, AI is just democratizing what many students have already been doing - paying someone to complete their assignments has been possible for a long time. AI simply lowers the barrier to entry, which is arguably a social good; it's no longer just the rich kids that can cheat.

The extent of AI-based cheating varies considerably by subject though. LLM AI struggles with solving physics problem sheets or designing chemistry experiments. On the other hand, it excels at providing plausible answers in fields like business, commerce, marketing, and programming, which happen to be subjects that attract a large number of international students.
[deleted]
They can also use AI to "check" if we used AI even though it's wildly inaccurate
Holy crap. This needs an investigative journalist to shine light on it. If we even have such people anymore.
I think the difference between calculators and AI is that a lot of integrals and matrices are either too difficult or too computationally heavy for a human to do by hand. A fantastic example of this is traffic foe problems, which often use thousandxthousand matrices to calculate the optimal flow. That is exceptionally computationally heavy and a computer can do it in an instant, but a human would take a month. Generative text programs like chatGPT removes free thinking and depth of thought from arguments, essays, and creative pieces. 

As a quick test, I used a generative AI to compare my above statement, written by a human, to an AI generated text block. I put in the prompt ‚Äúgenerate an argument against writers using AI and for engineers using calculators. Provide examples.‚Äù It spat out the following:

‚ÄúWriters rely on creativity, emotion, and nuanced language to craft unique narratives and connect with audiences; therefore using AI can dilute this artistic expression and lead to homogenized content. In contrast, engineers utilize calculators to enhance accuracy of complex calculations.‚Äù 

Note that whilst the arguments are similar to what I put out, the generative text did not provide any beyond-surface understanding of the topic, even when prompted to provide examples. It just gives a statement and provides no evidence or deeper insights. That‚Äôs the difference between AI and calculators; one enhances the accuracy and strength of human thought in a profession, and the other detracts from it.

Edit: TLDR AI has no depth and detracts from writing. Calculators and spell-check enhance their human applications
AI checkers are straight up bullshit and any that claim to be accurate just aren‚Äôt.
Yep absolutely. Bring back traineeships, cadetships, nursing and teaching schools so people can learn on the job for a few years rather than Unis producing people that employers need to train again anyway.
Uni has become a gatekeeper for intelligence and a mild level of grit. I‚Äôve employed a range of people with and without degrees - the people with degrees are nearly always better at the job.

I just put this down to - everyone who wants a knowledge based job goes to uni and the bar is very low as this thread suggests. If you can‚Äôt make it above that low bar then it‚Äôs usually that you have some issues with commitments of 3 or so years, and or you have learning/intelligence challenges.

So yeah in the past there were plenty of people who didn‚Äôt go to Uni that could learn on the job - say up to the 90s. Now however, since everyone goes to Uni, as an employer hiring talent, it‚Äôs just easier to screen out those without a degree, rather than look for the 1 in 20 people without a degree that have the capacity to learn on the job.¬†
This might be a controversial but I agree. I‚Äôm doing a course that‚Äôs going to be cost me over 40k with 2k per subject. I‚Äôm happy to do subject specific courses but they‚Äôre making me do 8 electives. I get the reasoning in that it will give me a broader world view and make me a more educated person. However, I‚Äôm paying 2k for these subjects when all I want is a piece of paper that allows me to get a job and the knowledge of how to do that job. Paying nearly 16 grand to do these electives feels like such a scam.
As someone with social anxiety, this would have destroyed me. I once forgot my own email address when a handyman asked. I can know the material very well but still get muddled up under pressure.
I agree, but the best argument I've heard against this is that it removes anonymity from assessments which then reintroduces bias into marking. Also, it definitely would be advantageous to more charismatic students, but I think you could structure the rubric and assessment process to privilege content over delivery. 

Maybe just doing it as brief zoom call with a teaching assistant where they ask you to expand on a few of your points and then note down your performance separately to whoever has anonymously marked your essay, and that makes up like 15% of the mark or something.
Nup. I do everything myself still. And the idea that I am the only one doing so fucking destroys me if I think about it too hard (especially when I‚Äôm late on a submission bc I don‚Äôt use it).
> There will come a point where AI-generated content can become indistinguishable from non-AI content

To a large extent, we're here already.

A potential solution is to rethink how we assess uni courses, and require students to demonstrate creative thinking in fresh scenarios. Lecturers and (especially) tutors, who know how the content is taught and know the capabilities of students, are well placed to assess this, they just need to be appropriately paid for taking the time to do so.

Unfortunately, this would require universities to care about anything other than the bottom line for just a few moments, so this won't get done.
This isn't AI hype. This is a thing that is currently happening.
It's like CLOUD remember? Everything is in the cloud, cloud this and that. The terminology will die down overtime just like cloud. It's the media buzz word at the moment.
> 
> 
>     A fucking tutor is who they are interviewing?

Tutor's not only mark assessment, but work directly with students and would be talking to them on the regular.

> if he‚Äôs second year. Is he just asking to read everyone‚Äôs papers? 

Uhh, second year students can also become tutors, he could also just be, y'know, talking to his fellow class mates and being part of groups that they're in?

> This article is basically completely made up by people that have zero authority or zero facts and is just making numbers up.

This is only true if you've no idea how uni is actually structured and assume everyone studies in a perfect silo?
Nope, the UK Master‚Äôs degree I taught in had 105 out of the first 120 credits (7/8 modules) taught with no exams whatsoever, only assignments. The last 60 credits are for the dissertation, which is just too inviting for international students not to use AI for. Thankfully when they failed my module miserably (because of the exam) they can‚Äôt get anything overturned because the department made sure everything is watertight.

I had enough this last year though and quit. Working in practice again now. Can‚Äôt keep working as a cog in a system that keeps churning out degrees to people who don‚Äôt deserve it.
What?  Don't you need to put your physical student card with photo on the top of your desk in exams anymore??
You're allowed to fail local students. You just can't fail full fee international students.
Have pen and pencil stopped working? Make your dumbass students start hand writing stuff.
We're becoming like the US The education standards are so bad because they need a certain average to keep their government funding. So they make it easier. More students passing with much less basic knowledge
We need universities that provide professional training for various vocations, not lifestyle adult childcare for students filling in for 3 years after school.  Pherhaps degrees that qualify you for a job, not ethereal halfway courses that need a masters to qualify you.
It is. Also, the amount of times I've seen the phrases "intricate tapestry" "unravel" "ever-evolving" "nuanced" and "shed light" is absurd üòÇ strangely increased only after ChatGPT became mainstream available. 

Surefire warning signs of AI use in student essays.
As someone who has to write a lot of essays I‚Äôm not entirely sure this is still good. It may sound dumb and academic but especially for a content heavy field you learn a lot of your weaknesses by actually writing it out, in the same way the first time you read a speech you find out where you fucked up in the process, essay writing is the same.

Sure some people hate it and I get that and not every field benefits from this fine comb approach but if you happen to be doing a degree that requires regular essay writing you are likely doing a course in which you benefit from such a process. Especially when AI is generally terrible at essay writing anyway (anyone who has had to grade essays knows the pain that it is looking over an obviously ai written work, it‚Äôs like Shakespeare without grammar)
That's a valid use for generative AI in my opinion. Honestly, I've used it from time to time as a way to structure my messy thoughts into more coherent writing for my research; I then rewrite the output so it doesn't sound like random robotic paragraphs are being sprinkled throughout my work. If you're feeding in your own ideas, and letting it help you rather than write for you, I dont have an issue when students use it (and holy shit sometimes their writing is so bad I WISH they used AI more)

We actually do make a point of AI being a TOOL not an answer. The red flags are the students who are consistently not engaged but suddenly produce text they don't understand.
> 
> 
> At least he understands the content and sources it, I guess. He just really hates writing and formatting essays lol.

I mean he understands how to find sources, but he has no ability to actually create knowledge from them, he's going to crash and burn big time when he actually gets out into the world and is asked to actually do things or express himself in any meaningful way. As someone that has to read a half dozen published papers every week, your friend would absolutely be one of the folks who may have something interesting they've stumbled upon but they're so fucking awful at actually talking about it, conveying their message or explaining what they're on about that they're doomed to never being actually read or used for anything.

Think back to every awful team meeting you've had at an office with that one person who is just awful to be there with, any time they have to present they just drone on and on and on and nobody has any idea what they're saying, that's your friend in 5 years time.
Yeah, that's the other problem with trying to stop the use of AI in a sweeping way. I don't think there's anything at all wrong with doing proper research and writing an essay yourself and then using an AI tool to tidy things up for you, but that will likely have similar tells to someone who gets the AI to write for them.
I don't disagree, but in almost every obvious use of generative AI I've graded, they've not scored well. They very much are surface level essays that barely address the deeper issues, and it's partly why the faculty I work for tends to not engage with academic misconduct when I flag them. 

"That student likely isn't getting a passing grade anyway, so it's not worth the effort" 

But yes, I think this is something we should move towards.
The problem is that by the time you create new standards and educate all the teachers in how to assess them, things have changed and now whatever weaknesses AI had compared to human writing are no longer such stand out flaws. It's made massive strides since ChatGPT was first released and it's only been a year and a half.
That's a genuinely great use, and I'm glad to hear it's helping you in your academic journey. 

Like I said, it's a great tool. It's just not appropriate to let it do the work FOR you; it sounds like you're using it appropriately!
It's slowly happening! We've had some very interesting new assessments. The students complain because they've not engaged with that structure before, but it makes GenAI hard to use and gets them thinking outside the box. 

Learning to think is more valuable than blindly memorising content anyway. 

There's doom and gloom about AI, but the academics who care are moving towards change.
Not OP but I studied psychology, and I feel like the hardest part would be citing everything. It'd be no good just having a wall of AI generated text. Unless AI is doing citations now too?
That won‚Äôt happen. Lawmaking is way slower than technological development (with some key exceptions). Ironically, a true sentient AI would be faster at lawmaking than people but that‚Äôs another ethics issue
Absolute rubbish.
It can give me tailored study tips, guides, definitions and explanations. I can give gpt a list of learning objectives and it can quiz me, telling me where I went wrong and what I need to focus on.
It will not (or I don‚Äôt make it, anyway) do the work or learning for me. It may reword things so I can understand it better, or it may give me tips to remember.
It‚Äôs not going anywhere, it needs to be integrated, not banned.
Except that's literally just you taking a shovel to your own foot, you got a HD but learnt literally nothing and just wasted your own and the universities time, the most hollow pyrrhic victory imaginable.
i was born and raised here and have east asian appearance and heritage. I needed to meet up with, who i later understood to be, the lecturers-in-charge of the course i wanted to transfer to for the next year. I needed their approval before i could do so.

I enter the room, greeted them. The dinosaur c\_unt who happens to fit that middle-aged, white guy demographic, smugly says to his second-in-charge woman lecturer something to the effect of, "oh, this one can speak english."

So he'd obviously already assumed I was an international student. Even if I was, that right there displayed a very condescending attitude on his behalf. You'd think there would be a standard of behaviour when it came to dealing with students, any students including international ones. 

If you thought that was inappropriate on his behalf, it kept getting worse. He began firing a line of questions at me that were none of his business and being very "catty" for a man. I could hardly get a word in edgeways and he was doing it deliberately to put me off kilter. The woman lecturer sitting beside him could only sit there in silence witnessing the whole thing and  perhaps feeling a minutia of sympathy for me. I get the sense sometimes that you can't win with racist white people because either a) they'll complain that you can't speak english or b) they get pissed that you actually are proficient in english because then they feel like they can't condescend to you as much when they are hellbent on belittling and demeaning you.

Got to the point where I was so shocked that I ended up glaring at him as if to say "what is your fucken problem?" That's when he started behaving properly and began to actually do what he was there for, addressing my transfer instead of him making his snarky comments.

F\_cking arsehole. This was a catholic tertiary institution too. So much for being a place of inclusivity and safety that learning institutions are supposed to be and you'd expect religious institutions to be more so, but nope. It's like they don't see this irony of what religious institutions are supposed to represent?

so yeah, this is the other side of the coin where people who look a certain way have to bear the brunt of the lecturer-in-charge's ire that is probably mixed in with a mentality that obviously harks back to the 1950s. There's a problem with having people who are too old teaching youth. Not all seniors but I've noticed a pattern where it's old people behaving like they're still stuck in a time warp more than any other cohort.  He may have his gripes with international students but keep it professional. Why isn't he taking it up with his local MP and the government?
I returned to study at about the same time. A major Uni, with a reputation as "The best" for that degree - and the entire back row of the class didn't speak a word of English.¬†


Somehow, despite the lectures being in English, that back row received top grades.


It was a very prestigious course with prices to match.


So if it didn't matter then. Why does the cheating matter now?
I had a 4th year honours tech student ask me what a style guide was
As a multiple-time group assignment survivor I'd have to agree.
As someone who has marked uni assignments, I can tell you that the lecturers and tutors have no idea who is paying upfront and who isn't. It isn't a conspiracy, just strict marking.
Those students don't have those issues. A lot of them were paying people to do their assignments.
I agree. I don‚Äôt think the students who are just there to pass will bother investing time in improving their writing skills. We don‚Äôt have such services at my university but I constantly send drafts of papers to my professors, implement the feedback and repeat. It seems like an automated system would save a lot of the teaching teams time.
> pre chat gpt guess what you were doing as a programmer or someone in IT?

This is only true for entry level positions, any serious sysadmin or systems engineer was absolutely not googling stackoverflow as solutions at that level just straight up don't exist as everything is so individualized to your organization and its setup. There's a lot more to IT than service desk jockey's and Tim the operator who wrote a powershell or two.
Your argument = everyone should be able to cheat! üòÇ
>  it excels at providing plausible answers in fields like business, commerce, marketing, and programming

It really doesn't beyond anything that isn't 100 or 200 courses, a friend does marking for a 400 level programming course and it's -blindingly- obvious when a student has used GPT because you just cannot fake it at that level.
Some of my programming courses required you to go through the code with the tutor and they will ask you about what individual sections did and why you implemented it in the manner you did.
Spot on, I started an engineering job last year while still studying and I have seen a grand total of 2 equations from university and had a decent baseline of using CAD software thanks to a class, the rest I've learnt on the job.
Your prompt did not specify that it needed depth.  Garbage in, garbage out
If using AI to write text produces bad text, and such bad text is submitted by the student, then the student should be marked down accordingly. 

These students are being accused of fraud for using AI tools. Period. Without any regard whether they've done it maliciously, or not. And my counter-argument is that using AI *alone* is not cheating.

For that matter, blindly plugging values into traffic algorithm I don't understand, and somehow producing correct values I can't explain, won't land me in academic probation either. It will land me with an F. So arguing this is merely a qualitative problem is a bit of a false equivalency.
seems like TAFE was always the better pathway, if it's possible for one's course, and then transferring to uni which will have chopped maybe a year or more off your degree and turned out substantially cheaper.

That's another thing that's a scam or at least, misguided. Schools pushing direct entry into uni when there's other cheaper and maybe better pathways.
I'm in exactly the same boat - I want to study public policy, which I'm really good at and interested in, but I'm being forced to study twice as long and pay twice as much to also do a whole lot of other subjects I'm less interested in and that are less relevant to my career interests. Most arts stuff can be learned very easily online without shelling out enormous sums of money.
I don't mean to be dismissive or insensitive (I have generalized anxiety with strong traits of social anxiety around performance) but I have a question:

I understand you being able to know the material, but in most real world contexts, you will be asked to, or have to convey somehow, what exactly it is that you know.

As far as most of my therapists have explained, most forms of anxiety are worsened by avoidance behaviour - that is, the more you try to insulate yourself from your fears, or try to avoid situations that you think will provoke the anxiety, the worse your anxiety will get.

Given the above, my initial thoughts are that ruling out any possibility of a student having to demonstrate their knowledge "live" does a disservice to all, as 

- It prevents all students from preparing themselves for the real-world scenarios they will have to face (when those real-world scenarios may have far more potential for negative impacts), and possibly learning more about the subject matter

- It possibly allows for the sort of cheating described in the article to flourish 

- It plays directly into the hands of the anxiety disorder (for those who have one).

However, I'd like to hear your view. Do you feel that being able to avoid situations where you had to engage in discussion of your work/knowledge helped you overcome your social anxiety? Or, did it help you expand your understanding of the subject matter?
AI is soooooooo awesome and amazing!!
cloud hasn't died down at all
I can‚Äôt speak for the entire UK system but, in my experience, Russell group universities (i.e. Oxbridge, LSE, UCL, et al) typically have assessment structures weighted 100% towards the final exam/exams. The assessment during the term is formative and doesn‚Äôt count towards a final grade. 

I suppose one could cheat in the dissertation but those tend to be subject to greater scrutiny.

Source: I studied for my postgrad at one of the aforementioned universities.
Had a friend who lectured and busted a massive plagiarism ring (across multiple years, heaps of students). Absolutely nothing happened, everyone still passed. International students are a protected species
Huge problem with aviation airline training in Australia for international cadets. The most clueless of them all still manage a near 100% pass in all exams‚Ä¶
Academics are doing this, handwritten assessments under exam conditions, where possible.
Many of the international students can‚Äôt even speak English, let alone write it.
Fuck that. I'm not disabled or anything like that but having to handwrite assignments would be a significant disadvantage for me. I have a much easier time thinking and making good content when it's typed. I can type just as fast as I can think, while I certainly can't do that while handwriting, and typing allows me to go back and change anything easily.
Or if is a masters make them do an oral to defend their thesis/argument.
lol i did primary in 2000 with a computer and used one through high school till uni in 2013 - 2018 again with a computer without the internet. because my hands were badly broken as a young child. i was failed for 13 years in high school English because i was unable to write the required papers by hand. but submitted far more detailed and complex papers then peers and classmates, that means i failed every single year in all subjects. because English is the only subject that counts in the Australian education system. fail that and  you get an automatic fat zero for all subjects. but i can type just fine at 150wpm. I"m very lucky that UNE was understanding and my choice of masters had no English requirement so i had no problems. the truly troubling part was that i had a 94 on my atar without English putting me in the top 2% of Australians. vs a 0 with English included. because it was an automatic fail at the time if it was not hand written.
Uh oh - I use 3/5 of those relatively frequently in my written work for uni.
Holy shit, I've been dealing with a co-worker that doesn't seem like he actually knows what he's talking about when you speak in person but can write these really wordy pieces that use language like that. I wonder if he's been using GPT...
I've definitely used the last three before. But I literally used to read the Dictionary and Thesaurus for fun as a child and teenager. I often had teachers accuse me of cheating on take home assignments until they got to know me and read enough of my in class essays. 

I've been accused of being AI before, on reddit. I haven't sought out any AI content but if it's anything like the copy pasted AI news articles I've read then I'm offended.
'Delve' is apparently a common one.

https://www.theguardian.com/technology/2024/apr/16/techscape-ai-gadgest-humane-ai-pin-chatgpt
Don't forget 'elevate"...
[deleted]
Yes and no.

Obviously an essential part of university is learning how to properly structure essays, format appropriate framework and ensure the writing is succinct, relevant and accurate.

Writing a basic framework and getting ai to do the rest defeats that purpose. Sure you can use the calculator analogy, but writing skills are still absolutely relevant and contribute to more than just good essays, they enhance critical thinking, logical flow, communication skills and succinct writing.
[deleted]
Essays that start with "Certainly, I can write you a report" are a red flag too
> They very much are surface level essays that barely address the deeper issues

They always read like that one high school kid who is using a thesaurus and just trying to pad out the word count, sentences that sound grandiose but upon the slightest inspection are hollow nothingness with a complete lack of any character or personality. Honestly most of the suspected cases could be sorted by just having a 5-10m catchup, wherein they had to answer questions and explain the concept on the spot to show that they have an actual understanding.
You‚Äôve received downvotes but you‚Äôre also right. What we need is major generative AI companies to also provide services to institutions to detect their AI usage, but unfortunately that would kill their bottom line so they won‚Äôt do it
>hings have changed and now whatever weaknesses AI had compared to human writing are no longer such stand out flaws

The weaknesses haven't changed, genAI text is as obvious as it always was. Unless if you work some job centred around useless marketing/corporate PR spam, which is what genAI generally tend toward I guess. genAI text is generally easy to spot because its language ignores the appropriate context of the field.  


>It's made massive strides since ChatGPT was first released and it's only been a year and a half.

It hasn't. It's actually getting worse, and model collapse is going to happen given how much genAI spam is already polluting the data they scrap from the internet. 

It's also stupid to assume things will necessarily improve, no tech is bound to always improve and the particular requirements for genAI to "improve" are not there and will never be there. It's a dead-end.

Finally, genAI generates no profit and is a massive money sink. The most likely outcome is that most of the available systems today will be dead in a couple of years because they cost too much to run.
> Learning to think is more valuable than blindly memorising content anyway.

It gets me that I wasn't allowed to solve projectile motion problems in physics via calculus (ie, use a general skill and understanding of the problem) and had to use a formula (ie, memorization).
Can you describe some of these new assessments?
I‚Äôm a psych student. We just finished an assessment where we were provided with AI generated essays (complete with citations and reference lists) and were tasked with correcting the information AI got wrong. A clever way to show students AI produces beautiful looking garbage.¬†
It's only slower because there is a HUGE business interest in keeping it slowed down, it's definitely corporations taking advantage of most peoples ignornace of the technology. There is nowhere near enough public pressure to create real chang even though we can see the problems arising right infront of us.
Catholic? Inclusive? lol
religious institutions are absolutely the opposite of inclusive, doesn't excuse that disgusting behaviour
>catholic tertiary institution

I was at a disbelief until you dropped this crucial piece of information.

Religion should be legislated, or even better, banned. before they legalize weed. Lol.
I reckon the ones that can‚Äôt speak English might not have HECS
i was replying in the same context to the person i was replying to, a uni environment
Well, either everyone or no one. At least it's a level playing field.
Is it really cheating if everyone is allowed to do it though?
Yes, that's an example of an oral defence. Difficult to cheat, though if conducted online you can hire someone to pretend to be you or feed you the answers.

AI continues to improve, too, and with something like Groq you can get instant explanations of code including reasonable answers to "why did you do it like this" or "what if you did this instead?".

Somewhat unrelated: my newest useful trick is using an LLM to do asymptotic complexity analysis on chunks of code. It can handle quite complex nested algorithms without me having to go through them manually, quite useful for code reviews.
The prompt I put in had the same depth as a typical essay prompt. Prompts are generally broad to allow for creativity, which is something that machine learning cannot do
I highly disagree. Using AI to write any portion of any essay in an academic or professional environment needs to be highly discouraged, no matter if it is malicious or not. Yes, I understand that using AI for finding some resources or understanding what a question is asking could be considered a valid use of it as a tool, however I am taking about use in particular for writing portions of an essay
I don't think it's an issue that we assess some things through those sorts of means, but it would definitely be really damaging to some people's ability to perform in educational contexts if that was something that went along with every form of assessment. I don't just have social anxiety; I'm autistic. Sure, maybe having to exercise those skills constantly would improve them, but there's always going to be the issue where my brain is extremely distracted by the social processing elements of that interaction. It would dramatically kneecap my performance. You could argue that maybe people who a disability could get a special exception, but I wasn't diagnosed until I was 25.
you might need a time machine if you never want to hear about it again.. might be a good idea to fit that time machine with some sort of AI too...
That's like asking everyone to shut up about smartphones or the internet.

It's not going anywhere. Every business/org you'll interact with, will use AI generators in some regard too.
My neighbour was teaching NURSING students, she said they all handed in the same work and couldn‚Äôt speak to it when asked.  For exams, they would pay someone to sit in for them and would get away with it.  I‚Äôm OK if Philosophy students cheat ~~fail~~ but I‚Äôd like nurses to actually know what they are doing.
UWA? Maybe a Computer engineering related unit?

Sounds familiar to something i remember way back.
Are they? I haven't heard of or seen this. Most unis have gone to fully online exams post-covid, even if they're done in person (i.e. you bring your laptop into an exam room). Don't think they'll be willing to go back to pen and paper exams due to cost and admin workload it adds. What I've seen in response to cheating in contemporary exam settings is actually a general move away from the use of exams for units where possible, or at least reducing their weight. Cheating has a bigger impact on exam scores that may have questions easily solved via cheating vs a long form 3500 word paper that required integrating deep domain specific and niche knowledge on a pared down topic. Sure, you can get AI to write you a paper but a) it can't write real citations to save its life and b) no sane marking scheme should every manage to pass a wholly AI written paper, beyond _maybe_ first year. Of course, the smarter and slightly competent student would use AI in a way that is better integrated and papers over it enough to deliver a competent piece, but I just don't see a way out of that situation other than basically allowing it
We are not allowed to make students sit exams in a room with a human watching (but we are a shit university)..‚Äùthat is for the dinosaurs‚Äù said our sub-dean L&T
Would u be younger than 25 by any chance?
Ok I don‚Äôt care? Hand write your work from now on to get your diploma stupid.
Same, but maybe it's just the younger generation who are much less likely to use those terms. Nuanced and shed light were relatively common in my writing.
There are heaps of AI checkers online, just copy and paste something from him into one.
it cracks me up when the spelling and grammar check in word always wants to change "high expectations" to "lofty expectations". I'm studying teaching and the language that is consistently used in the reference materials is definitely high expectations.
I'm quite aware. I don't instantly sound the sirens when I see these words, but it's noticeable when a large chunks of otherwise low scoring students all start using eerily similar vocabulary, over, and over, and over. 

My teaching and grading approach is far more nuanced than I can communicate in a casual Reddit post.
That's very true. Thanks for calling that out.Honestly, left unchecked I worry that the research landscape will become very homogenous. Good writers stand out, moreso in a sea of generative AI 

Perhaps I take writing for granted, it's a whole new generation that aren't engaging with written text in the same way many of us did growing up.
> Obviously an essential part of university is learning how to properly structure essays, format appropriate framework and ensure the writing is succinct, relevant and accurate.

Those that could afford it always had the option to hire a tutor who could ethically(to my understanding) fix the entire format of essays(even as just feedback which is then implemented) while leaving the arguments and research of the student intact as well as making sure everything is properly sourced and free of typos, grammar errors and odd word choices. Which can result in an incredible increase in grade.
I think we really need to build solid educational foundations and teach people how to work with AI and then it won't be an issue. If you have an understanding of what quality writing looks like, know what your goals are, and engage your brain while using AI, it can be a learning tool. It can help you find ways to express your ideas and then you can gain knowledge from that.
They truly are. I think this is one of the reasons there's a shift towards in-person exams being more heavily weighted (e.g, up to 50% of their overall grade). 

Times are changing. It's good to be guarded when it comes to incredible technology like genAI, but it's also exciting to see what it may evolve into. The brightest students still stand out regardless of the dunces barely scraping by with cheating.
You can use GPT for essays but it takes some effort.

Here‚Äôs a way I got a HD in an elective I didn‚Äôt give a fuck about.

1.	‚Å†Intake the course content (lecture videos etc), don‚Äôt actually have to do exercises which take a fuck ton of time.
2.	‚Å†Download lecture videos and put them through Open AI Whisper so it transcribes the entire lecture.
3.	‚Å†When you get to the assignment, copy the question into ChatGPT along with the relevant transcribed lecture content, it spits out exactly what the course content is and edit it and add relevant references to match ideal content needed.

This saves 10-15 hours of assignment writing time, 5-10 more hours on exercises, and shows how comically easy it is to cheat atleast a bit with some brainpower (although intaking course content is required).

Universities must require in class explanations for essays or in class paper tests for everything at this point.
I had an assessment last year where I was told to generate an essay using AI then critique it, whether that critique was positive or negative. 

The biggest thing that I noticed was that the AI used very long winded and verbose sentences without actually saying anything meaningful or interesting. 

The other thing I picked up was that it used the sources really badly- it either picked sources that weren‚Äôt academic, or it used relevant academic sources but cherry picked information from articles that wasn‚Äôt tightly related to the topic of the article. Information that was essentially being provided as background as part of the introduction. Bizarrely, even when the main topic of the article became relevant later in the essay the AI would use another random and largely irrelevant article instead of using any of the relevant information in the first one. 

In short, it didn‚Äôt write at all how I would expect a person to write.
I think detection for text will always be imperfect anyway, and false positives could cause a whole lot of damage. AI is part of the world now. What we need is to assume people will use it for some things and test them when they can't access it for others. It's going to be something people use in their work going forward, so trying to just cut it out of education entirely doesn't make sense. We need to teach people to use it without *mis*using it.
Even so detection will be very hard and there will be false positives. Some people do write in a pretty robotic way.

Can‚Äôt remember where I saw it but someone ran the King James (or possibly a more recent one) bible through one of those anti-plagiarism tools and yes, plenty of passages got flagged as AI.
I mean there are multiple ways of doing a problem like that. Calculus is a powerful tool to do so, but also just understanding vectors and conservation of momentum gives you enough information to do the same thing without memorizing a specific formula.
It just depends on the courses. For some of mine this year we‚Äôve had report formats that do not lend themselves well to AI - responding to specific case scenarios using specific references/frameworks, with following parts building on both case studies and previous answers. 


You can get GPT to write them, but it‚Äôs pretty shallow and obvious. Reflections have been reasonably AI proof, particularly when you‚Äôre asked to engage with the course readings and specific lectures, providing examples of your learning experience with them and understanding of them. 
In other subjects, like anatomy or physiology, there are the same old spot tests and labelling, but also things like ‚Äòhere are three images of haemoglobin mixed with these three solutions. What is the tonicity of the solution used in sample B?‚Äô
Or similar. You need to apply knowledge and examples in lectures and labs, but it‚Äôs not as easy to get a legit answer from GPT.


My uni has provided us access to copilot pro; and each class has a policy around generative AI. Some allow for idea generation, or structure assistance, ensuring you work in one document so you can show changes. Others will schedule 1:1s with a random selection of students from each grade (P,CR,DN, HD) to ask a couple questions about how you came to answers. Others ban it outright for anything submitted but encourage it for practice tests etc. 

The only thing I‚Äôve found it helpful for is practice multiple choice questions from a given list of learning objectives - suggested by my physiology lecturer and some general idea generation for a different assignment.
That is a pretty cool approach.
Lawmaking will always be slower in our current political climate because as soon as one side says ‚Äúregulate this‚Äù the other side shouts ‚ÄúNUH UH‚Äù and it becomes a stagnant issue. Yes, there are probably business interests affecting that, however technological advancements will always outpace lawmaking because of this
i'm learning...

remember when irish catholics were treated as the "other" and discriminated against in this country?

people have short memories or maybe they just deliberately block out this fact when they find other unfortunate groups to punch down on.
Just remove all special treatment and protections. If it's a worthy endeavour, let it stand on its own two feet. People shouldn't be coddled for their delusions.

What's this? Your deity isn't interceding on your behalf? Gee, I wonder why that could be?
Right, but I can tell you from experience that no one goes easier on those who can't speak English. If I couldn't understand their answer, they didn't get marks.
Using specific examples that were not a uni environment.
I used ai to write an abstract on my most recently submitted paper.. it did a fine job of summarising my work. Should I fail?
Why?
It‚Äôs fucking terrifying knowing that health workers of all professions are getting passed when they shouldn‚Äôt.  I am not surprised at all though considering how deeply ingrained corruption is in our society now.  We really are just a small step away from being a Banana Republic revolving around mining and money laundering through property.
>I‚Äôm OK if Philosophy students fail

I think you meant "cheat" right?  A philosophy student who cheated their way through a Bachelor of Arts is probably not much of a danger to society.
It's apparently a common story, I've had people guess almost every university 

Can't disclose anything because they weren't allowed to discuss it, unfortunately, but it wouldn't surprise anyone who was in those classes
My exams have all been closed book/can bring limited number of physical resources with pen and paper answer sheets since covid - you go into uni, connect up, and the questions are given online but you write/type out responses depending on the question, then take photos and upload answer sheets at the end

Depends on the uni and course I guess, 90% of my course (actuarial studies) is maths based though, which is naturally pretty AI proof (current AI tech often spits out factually incorrect answers to maths)
Yeah Melbourne Uni has in person invigilated exams with the students bringing their laptops and taking the exams via a lockdown browser (can‚Äôt access any other apps until exam is over). Desks have charging ports. Not perfect but I imagine reduces the chance of cheating a lot and also has the admin benefits of electronic exams.
Yes minimising the boost that LLMs may provide is also good. Marking handwritten assignments feels very old school, but yes a pain in the arse to coordinate
yup
It‚Äôs more when you see more than one of those keywords frequently that it becomes obvious. I tend to use nuance(d) in argumentative essays quite often, but don‚Äôt use the other keywords mentioned above. I also make sure to use it in exact contexts, rather than in a general application like generative text programs do. It‚Äôs quite obvious when someone is writing themselves as the arguments are much deeper and use more inflection rather than direct statements
Let's bring back *elucidate*
It's context dependent. You may use this wording in academic language but you can't expect students that barely know appropriate academic language to use them (especially at a high frequency).

In other contexts, this is also how you can detect your *academic colleagues* are using genAI (which I consider a form of disrespect) because common genAI phrases are often widely inappropriate for the paper you are writing.  

Everyone is shiting their pants about students' genAI use when we should also focus on the staff genAI use problem. It's not just weird papers in weird journals, it's your colleagues too.
Sure, but the same point applies.
> If you have an understanding of what quality writing looks like, know what your goals are, and engage your brain while using AI, it can be a learning tool.

Except not really, as learning quality writing, understanding your goals and engaging your brain will instantly have you writing works that are so far beyond what an AI is capable of, to the point that all it will do is drag your work down to a worse level.

> It can help you find ways to express your ideas and then you can gain knowledge from that.

Except that generally doesn't teach you as you haven't had to go through the thought process and haven't established any logical pathways or understandings, you've gone from A>E without understanding B,C,D which will help you be better informed in the future, it's a shortcut tool almost always as you could literally just reach out to your professor/tutor/classmates and have an actual conversation about ways to express yourself and actually gain something from it.
[deleted]
> incredible technology like genAI, but it's also exciting to see what it may evolve into

ü§£

GenAI is definitely not incredible, and it's quite close to collapsing already given how there is no sustainable economic model for it. It will "evolve" into... nothingness.
Congrats, you've now given your professor's carefully curated and hard won intellectual property to AI for free... which aside from being morally and legally questionable is also emotionally devastating for someone who cares about their lectures and course content.
> 
> 
> Here‚Äôs a way I got a HD in an elective I didn‚Äôt give a fuck about.

*Note, this only works for 100 level subjects, anything else you're going to look like a gigantic dickhead and it will be incredibly obvious you've not actually learnt anything at all.
A solution I‚Äôve seen here and there is anyone over a certain percentage of AI in a paper get called in for an interview about their work with all (or some) of the staff of the course. Or, do that for everyone. I know it would be a lot more time intensive but it would ensure people aren‚Äôt using it to write their papers
Yeah there will be false positives. That‚Äôs why any positives you get should be brought in to talk about subject matter and their essay. It becomes pretty obvious when someone is using AI when you talk to them cause they have no idea what the hell is going on
Same with polish catholics. I will never donate to Salvation Army as they shunned migrants who weren‚Äôt their type of Christian.

Tax them all.
Why are there students graduating university that can‚Äôt speak English?
Yes. You should not be using AI to write any part of your original work. I get that an abstract seems tedious but it‚Äôs also a part of writing a paper.
You are being assessed/paid for your work if people wanted generative AI to do the office jobs for them we would have seen massive layoffs recently. Generative AI does not have the depth of thought or inflective power that humanity has, so using it to write your essays for you is just stupid
and we vote for it!
It really is a common story my story on this is.

A coworker of mine found a cheating ring run by one of the other demos while doing demoing first year labs during her honors year, and when reporting it to the people running the subject nothing happened till she threatened to go to hand over her findings to the media, then and only then did the demo running the cheating ring get fired and I think that was it.

She apparently found out as the other demo was sharing past assignments, something about something she was marking tipped her off and then she got a student to show her the group chat this was happening in, which she just took screenshots of as her evidence.

This was at UTS and I believe mechanical engineering first year labs for reference. So a big reputable uni and for an important subject matter. I didn't go to that uni and I'm happy to share.
hahhaa that doesn't surprise me at all.
Basically every field beyond 100 and some 200 level subjects is AI proof, especially once you get into essay territory and actually providing novel thought or insight. AI is incredibly obvious when it comes to actually delving into a subject as it's the master of empty sentences, the entirety of the issue is vastly overblown outside of entry level subjects.
damn you guys get charging ports? at monash its up to you to figure it out. knew some ppl who went into 3hr exams with ancient pos laptops and died before the exam ended.
Ok fair that makes more sense. I Just joined the 30s club not too long ago and when writing down notes in meetings , I love the feel of pen and paper. I remember more than typing it out, where plastic keys   i find just feel cold, odd and unatural.  Im soley focused on hearing and typing that i dont even understand whats being said since i can just type it blindly via muscle memory.
How about *catharsis*? Although I never got far at uni‚Äîit may be more of a high school choice
I like that this is happening, gives a bit of hope to Uni students
Salvation Army is also notoriously homophobic and will throw LGBTA+ people out of their shelters if given the slightest excuse. Hideous charity tbh.
You're being paid for the benefit your work provides. As long as you've arrived to the result legally and morally, nobody cares how you did that. Empty, needless labor provides no benefit to anyone. Such labor is called a hobby.

We've addressed the quality argument already, but I'll re-iterate it once again for you. As long as the work meets the requirements, it is sufficient. You, not the AI, is responsible for the quality of work. And by extension, you are the ones judged over the quality of tools, such as the AI, that you use.

As a student, you are graded for both your understanding of the topic, and the ability to execute on it using standard tools. AI is a standard tool now. Judging someone's performance based on the sheer volume of written text alone is no longer a sufficient metric of evaluation.

Your argument makes it sound like it comes from point of fear for your livelihood being taken by someone who can better take advantage of modern tools.
No we don‚Äôt. 

The politicians don‚Äôt go into an election cycle saying they are going to give away university degrees to foreign students and undermine the institution.
practically based subjects are very notable for this. as a hardware engineer most of my 5 years of uni and virtually all my assessed work was hands on with custom equipment, servers, system engineering, and networking infrastructure. the theory was directly as a result of practical hands on experimentation and can not be found via other means. none of which any ai will help with,

plus based on the results I've seen hands on actively work to do serous damage. one of my favorites was the local tech turning up the humidity and destroying a 2 million dollar superdome compute that was 12 days old after chatgpt told him that low humidity could damage supercomputers computers. and he believed it. and this was just a month ago. 

 it never fails to amaze me how bad some of its "ideas" are. (adding sueprglue to pizza anyone? cooking pasta in petrol? how about washing laptops in liquid soap?)
One of the things the good LLM are best at is passing exams. If you want better quality responses from them the best practice is to word your prompt as an exam question.

This is simply because a very large part of the training sets for AI models is literally high level university exams questions for the inputs and student answers for outputs. As its the most available source of very high quality training data as it literally comes ranked and in a wide range of topics, and you can just get unis to shove AI outputs into actual exam marking to get validation of the models pretty cheaply. While also having a bench mark of what is and isn't good enough and a numerical comparison to human performance. This make training LLM with exams one of the most popular ways of training the models and because of this means they are very good at this.

There are endless articles news and scientific about chatgpt doing well in university exams. For example a meta study of 375 articles.

[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10938614/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10938614/)

Concluding with

>ChatGPT-3.5 performed satisfactorily in the exams it took as an examinee. However, there is a need for future related studies to fully explore the potential of ChatGPT in medical education.

Keep in mind 4 is much better at this then 3.5 at this.

Furthermore you have [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf) on page 5 going through a whole range of exam results for chatgpt4. with an important quote being

>GPT-4 exhibits human-level performance on the majority of these professional and academic exams. Notably, it passes a simulated version of the Uniform Bar Examination with a score in the top 10% of test takers (Table 1, Figure 4)

This is generally extremely widely reported that many types of exams are being passed with good marks. Now this isn't uniform across all subject so if you go look into the report I provided you can see it sucks at higher level programing but is great at the basic programming and for some reason that is beyond me is really good at chem 

And due to the chem skills it had to be manually filtered out from public version as it would give really good guides on how to make dangerous stuff, hence the memes about the Grandma exploit about her telling bed time stories about her making bombs and meth..
Rip that sucks so much!
i had a computer from the age of like 10 and I can type at >90wpm, while even fast handwriters struggle to go above 20. That's why I prefer typing.
My argument comes less from a fear of being replaced by someone using modern tools and more from a fear of an entire workforce being replaced entirely by automation, especially in a research field since research requires creativity that machine learning cannot provide. We are already seeing layoffs in production jobs because of automation, we cannot allow that to happen in every field out there because we will see mass poverty, which is never a good thing
most Australians, even the younger generation who has inherited a pile of shit, still vote for the two main parties that shat the pile of shit - if we aren‚Äôt aware that the two main parties in australia are going to act on behalf of other people who will make money off their decisions in return for donations and other kickbacks, then we aren‚Äôt really paying attention.  The Libs and Labour are in the back pocket of these corporations (and that‚Äôs exactly what universities have become). And it‚Äôs not random people running the show, Julie Bishop left politics and law to become the Vice Chancellor of ANU, do you think she isn‚Äôt using her influence to steer things toward her bank account?
So this was never about quality of work delivered using AI tools.
> most Australians, even the younger generation who has inherited a pile of shit, still vote for the two main parties that shat the pile of shit


[Of the 14,659,042 formal votes counted in the 2022 Federal Election:](https://results.aec.gov.au/27966/Website/HouseStateFirstPrefsByParty-27966-NAT.htm)

- 4,776,030 had ALP as first preference (32.58%)

- 3,502,713 had Liberal as first preference (23.89%)

- 1,795,985 had Greens as first preference (12.25%)

- 1,172,515 had Liberal National Party of Queensland as first preference (8%)

- 776,169 had Independent as first preference(5.29%)

- 727,464 had Pauline Hanson's One Nation as first preference (4.96%)

- 604,536 had United Australia Party as first preference (4.12%)

- 528,442 had The Nationals as first preference (3.60%)

- 252,963 had the Liberal Democratic Party as first preference (1.73%)

You can pretty much combine the Nationals with LNP QLD and Liberals as the **Coal**ition for 35.49% of the first preferences.   You can also virtually guarantee that UAP and PHON are proxy parties for the **Coal**ition which brings it up to 44.57% of first preferences.

The ALP is not as lucky as the **Coal**ition because they can't necessarily rely on any other party sending preferences their way so they need to negotiate with the likes of the Greens to get shit done more often than not.  

People love to blame the voters but the reality of the situation is that outside of CBD electorates there aren't that many options.  I see the Fusion party brought up in this subreddit often but the Fusion party only had 12 candidates last election.  Personally I would love to see more parties like the fusion party and sustainable australia party.

Which political parties do you think could make a difference?  How many candidates do they have running?
As of right now the quality of work is lower. If the current trend of increasing AI usage continues, humanity will genuinely be replaced by automation even in your standard jobs. In a capitalist society that will never end well. I‚Äôm a massive fan of workers rights, and the current trend leans towards workers getting less and less to drive up profiteering
